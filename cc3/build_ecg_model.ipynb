{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# from ecg import ecg_feature_computation\n",
    "import matplotlib.pyplot as plt\n",
    "# from hrvanalysis import get_time_domain_features,get_geometrical_features,get_csi_cvi_features,get_poincare_plot_features\n",
    "# from hrvanalysis import get_frequency_domain_features\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy.stats import iqr\n",
    "from enum import Enum\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score,classification_report\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from joblib import Parallel,delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_results(X,y,groups):\n",
    "    delta = 0.1\n",
    "    paramGrid = {'rf__kernel': ['rbf'],\n",
    "                 'rf__C': [1000],\n",
    "                 'rf__gamma': [np.power(2,np.float(x)) for x in np.arange(-6, -2, .25)],\n",
    "                 'rf__class_weight': [{0: w, 1: 1 - w} for w in [.2,.3,.25,.35]],\n",
    "                 'rf__probability':[True]\n",
    "    }\n",
    "    pca = PCA(n_components=4)\n",
    "    clf = Pipeline([('sts',StandardScaler()),('rf', SVC())])\n",
    "    gkf = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "    grid_search = GridSearchCV(clf, paramGrid, n_jobs=-1,cv=list(gkf.split(X,y,groups=groups)),\n",
    "                               scoring='f1',verbose=5)\n",
    "    X = X[:,np.array([2,3,4,5,6])]\n",
    "    grid_search.fit(X,y)\n",
    "    clf = grid_search.best_estimator_\n",
    "    y_pred = cross_val_predict(clf,X,y,cv=gkf.split(X,y,groups=groups),n_jobs=20)\n",
    "    clf.fit(X,y)\n",
    "    print(classification_report(y,y_pred))\n",
    "    return clf,np.array([f1_score(y,y_pred),precision_score(y,y_pred),recall_score(y,y_pred)])\n",
    "\n",
    "def get_label(user_data,st,et):\n",
    "    label = 2\n",
    "    for k in range(user_data.shape[0]):\n",
    "        if st>=user_data[k,0] and et<=user_data[k,1]:\n",
    "            label = user_data[k,2]\n",
    "\n",
    "    return label\n",
    "\n",
    "def get_ecg_windowss(rr_interval,window=0):\n",
    "    window_col,ts_col = [],[]\n",
    "    if window==0:\n",
    "        n = 30\n",
    "    else:\n",
    "        n = (.5*60)/(window/2)\n",
    "    ts_array = np.arange(rr_interval[0,0],rr_interval[-1,0],30000)\n",
    "    for t in ts_array:\n",
    "        index = np.where((rr_interval[:,0]>=t)&(rr_interval[:,0]<=t+60000))[0]\n",
    "        if len(index)<n:\n",
    "            continue\n",
    "        rr_temp = rr_interval[index,:]\n",
    "        window_col.append(rr_temp)\n",
    "        ts_col.append(t)\n",
    "    return window_col,ts_col\n",
    "\n",
    "def get_rr_features(a):\n",
    "    return np.array([np.var(a),iqr(a),np.mean(a),np.median(a),np.percentile(a,80),np.percentile(a,20),60000/np.median(a)])\n",
    "\n",
    "\n",
    "def combine_data_sobc(window_col,ts_col,label_data,participant):\n",
    "    feature_matrix = []\n",
    "    user_col = []\n",
    "    label_col = []\n",
    "    for i,item in enumerate(window_col):\n",
    "        feature = get_rr_features(item[:,1])\n",
    "        feature_matrix.append(feature.reshape(-1,7))\n",
    "        user_col.append(participant)\n",
    "        label_col.append(get_label(label_data,ts_col[i],ts_col[i]+50000))\n",
    "    return np.array(feature_matrix).reshape(-1,7),user_col,label_col\n",
    "\n",
    "def get_2_sec_ts(rr_ppg_int,window=2):\n",
    "    m = np.mean(rr_ppg_int[:,1])\n",
    "    s = np.std(rr_ppg_int[:,1])\n",
    "    ts_array = np.arange(rr_ppg_int[0,0],rr_ppg_int[-1,0],1000*window/2)\n",
    "    rr_interval = np.zeros((0,2))\n",
    "    for t in ts_array:\n",
    "        index = np.where((rr_ppg_int[:,0]>=t-1000*window//2)&(rr_ppg_int[:,0]<=t+1000*window//2))[0]\n",
    "        if len(index) < 1:\n",
    "            continue\n",
    "        rr_interval = np.concatenate((rr_interval,np.array([t,np.mean(rr_ppg_int[index,1])]).reshape(-1,2)))\n",
    "    return rr_interval\n",
    "\n",
    "\n",
    "def get_precision_recall_f1(path,window):\n",
    "    participants = os.listdir(path)\n",
    "    X,y,groups = np.zeros((0,7)),[],[]\n",
    "    for participant in participants:\n",
    "        file_list = os.listdir(path+'/'+participant)\n",
    "        for file in file_list:\n",
    "            final_path = path+'/'+participant+'/'+file+'/'\n",
    "            try:\n",
    "                if 'ecg_rr_pan_tomkins1.csv' not in os.listdir(final_path):\n",
    "                    continue\n",
    "                else:\n",
    "                    ecg_rr = pd.read_csv(final_path+'ecg_rr_pan_tomkins1.csv',header=None,sep=',').values\n",
    "                if ecg_rr.shape[0]<500:\n",
    "                    continue\n",
    "                winsor_limit = .02\n",
    "                ecg_rr[:,1] = winsorize(ecg_rr[:,1],limits=[winsor_limit,winsor_limit])\n",
    "                if window>0:\n",
    "                    ecg_rr = get_2_sec_ts(ecg_rr,window)\n",
    "                label_data = pd.read_csv(final_path+'label_data.csv',header=None,sep=',').values\n",
    "                window_col,ts_col = get_ecg_windowss(ecg_rr,window)\n",
    "                feature_matrix,user_col,label_col = combine_data_sobc(window_col,ts_col,label_data,participant)\n",
    "                rr_70th = np.percentile(feature_matrix[:,2],60)\n",
    "                rr_95th = np.percentile(feature_matrix[:,2],99)\n",
    "                index = np.where((feature_matrix[:,2]>rr_70th)&(feature_matrix[:,2]<rr_95th))[0]\n",
    "                means = np.mean(feature_matrix[index],axis=0)\n",
    "                stds = np.std(feature_matrix[index],axis=0)\n",
    "                feature_matrix = (feature_matrix - means)/stds\n",
    "                temp = np.array(label_col)\n",
    "                labels = np.array(label_col)\n",
    "                X = np.concatenate((X,feature_matrix))\n",
    "                y.extend(label_col)\n",
    "                groups.extend(user_col)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    y = np.array(y)\n",
    "    groups = np.array(groups)\n",
    "    index = np.where(y<2)[0]\n",
    "    X,y,groups = X[index],y[index],groups[index]\n",
    "#     print(X.shape,len(y),sum(y))\n",
    "    return get_results(X,y,groups)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 31 folds for each of 64 candidates, totalling 1984 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 354 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 552 tasks      | elapsed:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done 786 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1056 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1362 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1704 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1984 out of 1984 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.91      0.91      2350\n",
      "         1.0       0.74      0.75      0.74       836\n",
      "\n",
      "    accuracy                           0.87      3186\n",
      "   macro avg       0.82      0.83      0.83      3186\n",
      "weighted avg       0.87      0.87      0.87      3186\n",
      "\n",
      "[0, 0.7446555819477436, 0.7393867924528302, 0.75]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.mstats_basic import winsorize\n",
    "import pickle\n",
    "path = '/home/jupyter/mullah/Test/data_yield/data/sobc_2nd_chance//'\n",
    "all_results = []\n",
    "for duration in [0]:\n",
    "    clf,temp = get_precision_recall_f1(path,duration)\n",
    "    temp = [duration]+list(temp)\n",
    "    all_results.append(np.array(temp))\n",
    "    pickle.dump(all_results,open('../data/rice/stress_results.p','wb'))\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf,open('../models/stress_ecg_final.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pickle.load(open('../data/rice/stress_results.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.array(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':20})\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(np.array(range(0,df.shape[0]*4,4)),df[:,1],1,label='F1 score')\n",
    "plt.bar(np.array(range(1,df.shape[0]*4,4)),df[:,2],1,label='Precision score')\n",
    "plt.bar(np.array(range(2,df.shape[0]*4,4)),df[:,3],1,label='Recall score')\n",
    "plt.xticks(np.array(range(1,df.shape[0]*4,4)),['No \\n smoothing']+list(np.arange(2,16,1)),rotation=60)\n",
    "plt.xlabel('Moving Average Duration')\n",
    "plt.legend(ncol=3)\n",
    "plt.title('Stress Detection from ECG')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "y = np.array(y)\n",
    "groups = np.array(groups)\n",
    "y = y[~np.isnan(X).any(axis=1)]\n",
    "groups = groups[~np.isnan(X).any(axis=1)]\n",
    "X = X[~np.isnan(X).any(axis=1)]\n",
    "print(X.shape,len(np.unique(groups)))\n",
    "for user in np.unique(groups):\n",
    "    index = np.where(groups==user)[0]\n",
    "    X[index,:] = StandardScaler().fit_transform(X[index,:])\n",
    "# X[X>4] = 4\n",
    "# X[X<-4] = -4\n",
    "index = np.where(y<2)[0]\n",
    "X,y,groups = X[index],y[index],groups[index]\n",
    "print(X.shape,len(np.unique(groups)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "m = len(np.where(y==0)[0])\n",
    "n = len(np.where(y>0)[0])\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "delta = 0.1\n",
    "\n",
    "paramGrid = {'rf__kernel': ['rbf'],\n",
    "             'rf__C': [11,1000],\n",
    "             'rf__gamma': [np.power(2,np.float(x)) for x in np.arange(-6, -2, .25)],\n",
    "             'rf__class_weight': [{0: w, 1: 1 - w} for w in [.2,.3,.25,.35]],\n",
    "             'rf__probability':[True]\n",
    "}\n",
    "pca = PCA(n_components=4)\n",
    "clf = Pipeline([('sts',StandardScaler()),('rf', SVC())])\n",
    "gkf = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "grid_search = GridSearchCV(clf, paramGrid, n_jobs=-1,cv=list(gkf.split(X,y,groups=groups)),\n",
    "                           scoring='accuracy',verbose=5)\n",
    "grid_search.fit(X[:,:],y)\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.metrics import classification_report\n",
    "warnings.filterwarnings('ignore')\n",
    "clf = grid_search.best_estimator_\n",
    "y_pred = cross_val_predict(clf,X,y,cv=gkf.split(X,y,groups=groups),n_jobs=20)\n",
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "print(clf)\n",
    "clf.fit(X,y)\n",
    "pickle.dump(clf,open('../models/stress_model_ecg_2.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mats = confusion_matrix(y,y_pred)\n",
    "mats\n",
    "# sns.set(font_scale=1.5)\n",
    "# df_cm = pd.DataFrame(mats, index = [i for i in ['Not Stress','Stress']],\n",
    "#                   columns = [i for i in ['Not Stress','Stress']])\n",
    "# plt.figure(figsize = (10,7))\n",
    "# sns.heatmap(df_cm, annot=True,fmt='g',annot_kws={\"fontsize\":28})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "# import parfit.parfit as pf\n",
    "from sklearn.base import clone, is_classifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,accuracy_score,classification_report\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from sklearn.model_selection import check_cv\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ParameterSampler, ParameterGrid\n",
    "from sklearn.utils.validation import _num_samples, indexable\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "\n",
    "def Twobias_scorer_CV(probs, y, ret_bias=False):\n",
    "    db = np.transpose(np.vstack([np.array(probs).reshape(-1), np.array(y).reshape(-1)]))\n",
    "    db = db[np.argsort(db[:, 0]), :]\n",
    "\n",
    "    pos = np.sum(y == 1)\n",
    "    n = len(y)\n",
    "    neg = n - pos\n",
    "    tp, tn = pos, 0\n",
    "    lost = 0\n",
    "\n",
    "    optbias = []\n",
    "    minloss = 1\n",
    "\n",
    "    for i in range(n):\n",
    "        #\t\tp = db[i,1]\n",
    "        if db[i, 1] == 1:  # positive\n",
    "            tp -= 1.0\n",
    "        else:\n",
    "            tn += 1.0\n",
    "\n",
    "        # v1 = tp/pos\n",
    "        #\t\tv2 = tn/neg\n",
    "        if tp / pos >= 0.95 and tn / neg >= 0.95:\n",
    "            optbias = [db[i, 0], db[i, 0]]\n",
    "            continue\n",
    "\n",
    "        running_pos = pos\n",
    "        running_neg = neg\n",
    "        running_tp = tp\n",
    "        running_tn = tn\n",
    "\n",
    "        for j in range(i + 1, n):\n",
    "            #\t\t\tp1 = db[j,1]\n",
    "            if db[j, 1] == 1:  # positive\n",
    "                running_tp -= 1.0\n",
    "                running_pos -= 1\n",
    "            else:\n",
    "                running_neg -= 1\n",
    "\n",
    "            lost = (j - i) * 1.0 / n\n",
    "            if running_pos == 0 or running_neg == 0:\n",
    "                break\n",
    "\n",
    "            # v1 = running_tp/running_pos\n",
    "            #\t\t\tv2 = running_tn/running_neg\n",
    "\n",
    "            if running_tp / running_pos >= 0.95 and running_tn / running_neg >= 0.95 and lost < minloss:\n",
    "                minloss = lost\n",
    "                optbias = [db[i, 0], db[j, 0]]\n",
    "\n",
    "    if ret_bias:\n",
    "        return -minloss, optbias\n",
    "    else:\n",
    "        return -minloss\n",
    "def cv_fit_and_score(estimator, X, y, scorer, parameters, cv):\n",
    "    \"\"\"Fit estimator and compute scores for a given dataset split.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object implementing 'fit'\n",
    "        The object to use to fit the data.\n",
    "    X : array-like of shape at least 2D\n",
    "        The data to fit.\n",
    "    y : array-like, optional, default: None\n",
    "        The target variable to try to predict in the case of\n",
    "        supervised learning.\n",
    "    scorer : callable\n",
    "        A scorer callable object / function with signature\n",
    "        ``scorer(estimator, X, y)``.\n",
    "    parameters : dict or None\n",
    "        Parameters to be set on the estimator.\n",
    "    cv:\tCross-validation fold indeces\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "        CV score on whole set.\n",
    "    parameters : dict or None, optional\n",
    "        The parameters that have been evaluated.\n",
    "    \"\"\"\n",
    "    estimator.set_params(**parameters)\n",
    "    cv_probs_ = cross_val_probs(estimator, X, y, cv)\n",
    "    score = scorer(cv_probs_, y)\n",
    "\n",
    "    return [score, parameters]  # scoring_time\n",
    "    \n",
    "def cross_val_probs(estimator, X, y, cv):\n",
    "    probs = np.zeros(len(y))\n",
    "    probs = cross_val_predict(estimator, X, y, cv=cv,method='predict_proba')[:,1]\n",
    "#     for train, test in cv:\n",
    "#         temp = estimator.fit(X[train], y[train]).predict_proba(X[test])\n",
    "#         probs[test] = temp[:, 1]\n",
    "\n",
    "    return probs\n",
    "\n",
    "def f1Bias_scorer_CV(probs, y, ret_bias=False):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y, probs)\n",
    "\n",
    "    f1 = 0.0\n",
    "    for i in range(0, len(thresholds)):\n",
    "        if not (precision[i] == 0 and recall[i] == 0):\n",
    "            f = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
    "            if f > f1:\n",
    "                f1 = f\n",
    "                bias = thresholds[i]\n",
    "\n",
    "    if ret_bias:\n",
    "        return f1, bias\n",
    "    else:\n",
    "        return f1\n",
    "    \n",
    "class ModifiedGridSearchCV(GridSearchCV):\n",
    "    def __init__(self, estimator, param_grid, scoring=None, fit_params=None,\n",
    "                 n_jobs=1, iid=True, refit=True, cv=None, verbose=0,\n",
    "                 pre_dispatch='2*n_jobs', error_score='raise'):\n",
    "\n",
    "        super(ModifiedGridSearchCV, self).__init__(\n",
    "                estimator, param_grid, scoring, fit_params, n_jobs, iid,\n",
    "                refit, cv, verbose, pre_dispatch, error_score)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Actual fitting,  performing the search over parameters.\"\"\"\n",
    "\n",
    "        parameter_iterable = ParameterGrid(self.param_grid)\n",
    "\n",
    "        estimator = self.estimator\n",
    "        cv = self.cv\n",
    "\n",
    "        n_samples = _num_samples(X)\n",
    "        X, y = indexable(X, y)\n",
    "\n",
    "        if y is not None:\n",
    "            if len(y) != n_samples:\n",
    "                raise ValueError('Target variable (y) has a different number '\n",
    "                                 'of samples (%i) than data (X: %i samples)'\n",
    "                                 % (len(y), n_samples))\n",
    "#         cv = check_cv(cv, X, y, classifier=is_classifier(estimator))\n",
    "\n",
    "        if self.verbose > 0:\n",
    "#             if isinstance(parameter_iterable, Sized):\n",
    "            n_candidates = len(parameter_iterable)\n",
    "            print(\"Fitting {0} folds for each of {1} candidates, totalling\"\n",
    "                  \" {2} fits\".format(len(cv), n_candidates,\n",
    "                                     n_candidates * len(cv)))\n",
    "\n",
    "        base_estimator = clone(self.estimator)\n",
    "\n",
    "        pre_dispatch = self.pre_dispatch\n",
    "\n",
    "        out = Parallel(\n",
    "                n_jobs=self.n_jobs, verbose=self.verbose,\n",
    "                pre_dispatch=pre_dispatch\n",
    "        )(\n",
    "                delayed(cv_fit_and_score)(clone(base_estimator), X, y, self.scoring,\n",
    "                                          parameters, cv=cv)\n",
    "                for parameters in parameter_iterable)\n",
    "#         print(out)\n",
    "        best = sorted(out,key=lambda x: x[0], reverse=True)[0]\n",
    "        self.best_params_ = best[1]\n",
    "        self.best_score_ = best[0]\n",
    "\n",
    "        if self.refit:\n",
    "            # fit the best estimator using the entire dataset\n",
    "            # clone first to work around broken estimators\n",
    "            best_estimator = clone(base_estimator).set_params(\n",
    "                    **best[1])\n",
    "#             if y is not None:\n",
    "#                 best_estimator.fit(X, y, **self.fit_params)\n",
    "#             else:\n",
    "#                 best_estimator.fit(X, **self.fit_params)\n",
    "            self.best_estimator_ = best_estimator\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "X1 = preprocessing.StandardScaler().fit_transform(X)\n",
    "delta = 0.1\n",
    "parameters1 = {'kernel': ['rbf'],\n",
    "              'C': np.logspace(0,2,2),\n",
    "              'gamma': np.logspace(-9,9,10),\n",
    "              'class_weight': [{0: w, 1: 1 - w} for w in np.arange(0.0, 1.0, delta)],\n",
    "              'probability':[True],\n",
    "              'verbose':[False],\n",
    "              'cache_size':[2000]}\n",
    "parameters = {\n",
    "    'min_samples_leaf': [4],\n",
    "    'max_features': [.7,1],\n",
    "    'n_estimators': [100,200,300],\n",
    "    'n_jobs': [-1],\n",
    "    'criterion':['gini','entropy'],\n",
    "    'class_weight': [{0: w, 1: 1 - w} for w in np.arange(0.0, 1.0, delta)],\n",
    "    'random_state': [42]\n",
    "       }\n",
    "svc = SVC()\n",
    "# svc = RandomForestClassifier()\n",
    "# grid_search = GridSearchCV(svc,parameters, cv=gkf.split(X1,y,groups=groups), \n",
    "#              n_jobs=-1, scoring='f1', verbose=1, iid=False)\n",
    "# clf = Pipeline([('sts',StandardScaler()),('clf',svc)])\n",
    "grid_search = ModifiedGridSearchCV(svc, parameters1, cv=list(gkf.split(X1,y,groups=groups)),\n",
    "                                   n_jobs=20, scoring=f1Bias_scorer_CV, verbose=1, iid=False)\n",
    "grid_search.fit(X1,y)\n",
    "clf = grid_search.best_estimator_\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(np.where(y==0)[0])\n",
    "n = len(np.where(y>0)[0])\n",
    "clf.probability = True\n",
    "CV_probs = cross_val_probs(clf, X1, y, gkf.split(X1,y,groups=groups))\n",
    "# score, bias = Twobias_scorer_CV(CV_probs, y, True)\n",
    "score, bias = f1Bias_scorer_CV(CV_probs, y, True)\n",
    "predicted = np.asarray(CV_probs >= bias, dtype=np.int)\n",
    "classified = range(n)\n",
    "print(score,bias)\n",
    "\n",
    "f = np.zeros((len(y),2))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "print(metrics.classification_report(y, predicted))\n",
    "print(metrics.confusion_matrix(y, predicted))\n",
    "\n",
    "data['groups'] = groups\n",
    "data['original'] = [[i] for i in y]\n",
    "data['predicted'] = [[i] for i in predicted]\n",
    "f_scores = []\n",
    "data = data.groupby('groups').sum()\n",
    "for i in range(data.shape[0]):\n",
    "    f_scores.append(f1_score(data['original'][i],data['predicted'][i]))\n",
    "print(np.median(f_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score\n",
    "import itertools\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict, GroupKFold,GridSearchCV\n",
    "def plot_confusion_matrix(cm, classes=['Not Stress','Stress'],\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('result.png')\n",
    "    plt.show()\n",
    "gkf = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "predicted = cross_val_predict(clf, X, y, cv=gkf.split(X,y,groups=groups),n_jobs=24)\n",
    "plot_confusion_matrix(confusion_matrix(y,predicted))\n",
    "print(f1_score(y,predicted),precision_score(y,predicted),recall_score(y,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "svc = predictor\n",
    "gkf = GroupKFold(n_splits=len(np.unique(groups)))\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=gkf.split(X,y,groups=groups),\n",
    "              scoring='f1',n_jobs=24)\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1/2,1/3,1/6],[0,1/3,2/3],[1/2,0,1/2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(np.matmul(a,a),a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.float.as_integer_ratio(0.36111111)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3",
   "language": "python",
   "name": "cc3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
