{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebralcortex.util.helper_methods import get_study_names\n",
    "sn = get_study_names(\"/home/jupyter/cc3_conf/\")\n",
    "print(sn)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType,MapType, StringType,ArrayType, FloatType, TimestampType, IntegerType\n",
    "from pyspark.sql.functions import minute, second, mean, window\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cerebralcortex.core.datatypes import DataStream\n",
    "from cerebralcortex.core.metadata_manager.stream.metadata import Metadata, DataDescriptor, \\\n",
    "ModuleMetadata\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "from cerebralcortex import Kernel\n",
    "CC = Kernel(\"/home/jupyter/cc3_conf/\", study_name='md2k_aa_rice')\n",
    "\n",
    "def save_data(ppg_likelihood,stream_name,description='blank'):\n",
    "    schema = ppg_likelihood._data.schema\n",
    "    stream_metadata = Metadata()\n",
    "    stream_metadata.set_name(stream_name).set_description(description)\n",
    "    for field in schema.fields:\n",
    "        stream_metadata.add_dataDescriptor(\n",
    "            DataDescriptor().set_name(str(field.name)).set_type(str(field.dataType))\n",
    "        )\n",
    "    stream_metadata.add_module(\n",
    "        ModuleMetadata().set_name(description) \\\n",
    "        .set_attribute(\"url\", \"https://md2k.org\").set_author(\n",
    "            \"Md Azim Ullah\", \"mullah@memphis.edu\"))\n",
    "    stream_metadata.is_valid()\n",
    "#     ppg_likelihood.printSchema()\n",
    "    ds = DataStream(data=ppg_likelihood._data,metadata=stream_metadata)\n",
    "    CC.save_stream(ds,overwrite=False)\n",
    "users = ['35109a64-411d-4768-9602-c0a3d519a088','9b3e5f2e-99e8-4c4c-8580-6f4e2b107e37','3febca74-f12b-4a1b-a469-22d6cad30e74',\n",
    "         'f35c1279-806e-4546-839b-037ee01b0116','19223eac-7f2e-429c-8fa7-0977eee8ae7c','5a47080d-a1ec-48f2-a174-a6a017fcb100',\n",
    "         '099b45df-6432-47d2-8332-a8a870ec79de','903c1dae-a771-405f-a021-6f175724adc4','ad1e878e-7bea-48ca-b890-92770fe02a4c',\n",
    "         'd768791c-7479-4aaf-a6c8-61e82f1517e8','780e89b3-f6bf-4181-9f2c-7db941735c87','8008f00d-2549-46e4-ab1f-01542c1076e2',\n",
    "         '34e42cf6-7c34-417c-a003-874e3b6151e7','e099e913-4796-4408-af63-1d35c84f29fd','d3cf5812-85fd-4328-9b2a-1b3b6b2cd0b0',\n",
    "         'b0954814-ad5a-4a8f-ac5a-8436a70889d0','0c2f18b6-142e-4e9a-ab1b-4d4ea2e91280','bde40f50-8e35-4707-8260-b69f07773c4d',\n",
    "         '98fca87c-9940-4666-9893-9f8ae2418cb8','780f84d0-eb06-4696-a47d-9320bc17d117','808b555a-6573-457e-b1c6-e008594b0f9a',\n",
    "         'cd575a70-f1a4-4a2b-ac0d-dd0c330a7912','bb0fe5f5-798b-45ea-be50-8e56e3116369','a19eb22e-8c99-42d5-8a68-caad1dfe9361',\n",
    "         '9998aedf-5144-4402-9806-fd0965ca85c0','f0286b14-18d2-46bd-845e-f83b43a2ef7b','a94e78e6-acb4-4a71-920a-92b1858d51bd',\n",
    "         '5f3f7553-6d2f-4c08-adb9-dbc3e88ba0aa','b71b2071-6330-434d-a2ab-8e929e9b96a9','b53e7168-0a87-4646-b389-fb0fe60cc36a',\n",
    "         '9197be51-f220-4c63-a6a8-3ec1bbd50810','892e71e0-a5a4-4315-89a4-fa5518d78591','96f6e25f-4dd0-4070-a9ac-b04957969382',\n",
    "         'cfe02b15-0332-4590-9ac6-9ef2eb8b3edd','896d9cb5-2e54-4900-9b8a-58c087549d19','ea2fa266-3e43-4552-8c74-cba474ae0038',\n",
    "         '263b1782-923d-4bb3-b52d-4c1926e81f1f','9bc2eed3-f75d-479c-9665-75df853bc8ac','9744e4ae-63d8-49df-be6a-37cbb24532a1',\n",
    "         '2d8b5a8c-e990-4442-abf6-578e96d2f5eb','897fdfcf-9004-4ef6-bf9a-8d3fe339c8ce','9a3bd464-f273-4f97-a48c-1f3c6a705a69']\n",
    "\n",
    "# '6ef875b3-2f7e-48b8-bf00-de3ee1316830','05846fcf-1dd9-4f98-b17b-1ce6e624c0a7','4bf6078d-afcd-432a-a8a5-8b5e8a4eda9e','2333036a-2f50-49ca-a119-3c5d66399fe4',\n",
    "# '22c85326-97bf-4e4b-90c4-4255c144ae1b','f8d33ca1-e0fa-4b59-a7c2-b1aee8afcaea','c64ca471-369e-43fa-a07b-8260fd1c745c','fdddb3bd-bb88-458f-bcc8-e50bb3f87742',\n",
    "# '02543bbf-84c2-4076-8547-c8a5f451ea02','0c726695-f016-4019-9aab-c292298ee10c','87a2bf88-ef4e-4bd5-96b6-eda8faac6a8e','8d96c9a4-a13b-4729-adf3-969e84b9a6d2']\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.stats import skew,kurtosis,iqr\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "import logging\n",
    "from math import pi, log\n",
    "import numpy as np\n",
    "import pylab\n",
    "from scipy import fft, ifft\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import cspline1d_eval, cspline1d\n",
    "\n",
    "def _datacheck_peakdetect(x_axis, y_axis):\n",
    "    if x_axis is None:\n",
    "        x_axis = range(len(y_axis))\n",
    "    \n",
    "    if len(y_axis) != len(x_axis):\n",
    "        raise ValueError( \n",
    "                \"Input vectors y_axis and x_axis must have same length\")\n",
    "    \n",
    "    #needs to be a numpy array\n",
    "    y_axis = np.array(y_axis)\n",
    "    x_axis = np.array(x_axis)\n",
    "    return x_axis, y_axis\n",
    "    \n",
    "\n",
    "def _pad(fft_data, pad_len):\n",
    "    \"\"\"\n",
    "    Pads fft data to interpolate in time domain\n",
    "    \n",
    "    keyword arguments:\n",
    "    fft_data -- the fft\n",
    "    pad_len --  By how many times the time resolution should be increased by\n",
    "    \n",
    "    return: padded list\n",
    "    \"\"\"\n",
    "    l = len(fft_data)\n",
    "    n = _n(l * pad_len)\n",
    "    fft_data = list(fft_data)\n",
    "    \n",
    "    return fft_data[:l // 2] + [0] * (2**n-l) + fft_data[l // 2:]\n",
    "    \n",
    "def _n(x):\n",
    "    \"\"\"\n",
    "    Find the smallest value for n, which fulfils 2**n >= x\n",
    "    \n",
    "    keyword arguments:\n",
    "    x -- the value, which 2**n must surpass\n",
    "    \n",
    "    return: the integer n\n",
    "    \"\"\"\n",
    "    return int(log(x)/log(2)) + 1\n",
    "    \n",
    "    \n",
    "def _peakdetect_parabola_fitter(raw_peaks, x_axis, y_axis, points):\n",
    "    func = lambda x, a, tau, c: a * ((x - tau) ** 2) + c\n",
    "    fitted_peaks = []\n",
    "    distance = abs(x_axis[raw_peaks[1][0]] - x_axis[raw_peaks[0][0]]) / 4\n",
    "    for peak in raw_peaks:\n",
    "        index = peak[0]\n",
    "        x_data = x_axis[index - points // 2: index + points // 2 + 1]\n",
    "        y_data = y_axis[index - points // 2: index + points // 2 + 1]\n",
    "        # get a first approximation of tau (peak position in time)\n",
    "        tau = x_axis[index]\n",
    "        # get a first approximation of peak amplitude\n",
    "        c = peak[1]\n",
    "        a = np.sign(c) * (-1) * (np.sqrt(abs(c))/distance)**2\n",
    "        \"\"\"Derived from ABC formula to result in a solution where A=(rot(c)/t)**2\"\"\"\n",
    "        \n",
    "        # build list of approximations\n",
    "        \n",
    "        p0 = (a, tau, c)\n",
    "        popt, pcov = curve_fit(func, x_data, y_data, p0)\n",
    "        # retrieve tau and c i.e x and y value of peak\n",
    "        x, y = popt[1:3]\n",
    "        \n",
    "        # create a high resolution data set for the fitted waveform\n",
    "        x2 = np.linspace(x_data[0], x_data[-1], points * 10)\n",
    "        y2 = func(x2, *popt)\n",
    "        \n",
    "        fitted_peaks.append([x, y, [x2, y2]])\n",
    "        \n",
    "    return fitted_peaks\n",
    "    \n",
    "    \n",
    "def peakdetect_parabole(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Misspelling of peakdetect_parabola\n",
    "    function is deprecated please use peakdetect_parabola\n",
    "    \"\"\"\n",
    "    logging.warn(\"peakdetect_parabole is deprecated due to misspelling use: peakdetect_parabola\")\n",
    "    \n",
    "    return peakdetect_parabola(*args, **kwargs)\n",
    "    \n",
    "    \n",
    "def peakdetect(y_axis, x_axis = None, lookahead = 200, delta=0):\n",
    "    max_peaks = []\n",
    "    min_peaks = []\n",
    "    dump = []   #Used to pop the first hit which almost always is false\n",
    "       \n",
    "    # check input data\n",
    "    x_axis, y_axis = _datacheck_peakdetect(x_axis, y_axis)\n",
    "    # store data length for later use\n",
    "    length = len(y_axis)\n",
    "    \n",
    "    \n",
    "    #perform some checks\n",
    "    if lookahead < 1:\n",
    "        raise ValueError(\"Lookahead must be '1' or above in value\")\n",
    "    if not (np.isscalar(delta) and delta >= 0):\n",
    "        raise ValueError(\"delta must be a positive number\")\n",
    "    \n",
    "    #maxima and minima candidates are temporarily stored in\n",
    "    #mx and mn respectively\n",
    "    mn, mx = np.Inf, -np.Inf\n",
    "    \n",
    "    #Only detect peak if there is 'lookahead' amount of points after it\n",
    "    for index, (x, y) in enumerate(zip(x_axis[:-lookahead], \n",
    "                                        y_axis[:-lookahead])):\n",
    "        if y > mx:\n",
    "            mx = y\n",
    "            mxpos = x\n",
    "        if y < mn:\n",
    "            mn = y\n",
    "            mnpos = x\n",
    "        \n",
    "        ####look for max####\n",
    "        if y < mx-delta and mx != np.Inf:\n",
    "            #Maxima peak candidate found\n",
    "            #look ahead in signal to ensure that this is a peak and not jitter\n",
    "            if y_axis[index:index+lookahead].max() < mx:\n",
    "                max_peaks.append([mxpos, mx])\n",
    "                dump.append(True)\n",
    "                #set algorithm to only find minima now\n",
    "                mx = np.Inf\n",
    "                mn = np.Inf\n",
    "                if index+lookahead >= length:\n",
    "                    #end is within lookahead no more peaks can be found\n",
    "                    break\n",
    "                continue\n",
    "            #else:  #slows shit down this does\n",
    "            #    mx = ahead\n",
    "            #    mxpos = x_axis[np.where(y_axis[index:index+lookahead]==mx)]\n",
    "        \n",
    "        ####look for min####\n",
    "        if y > mn+delta and mn != -np.Inf:\n",
    "            #Minima peak candidate found \n",
    "            #look ahead in signal to ensure that this is a peak and not jitter\n",
    "            if y_axis[index:index+lookahead].min() > mn:\n",
    "                min_peaks.append([mnpos, mn])\n",
    "                dump.append(False)\n",
    "                #set algorithm to only find maxima now\n",
    "                mn = -np.Inf\n",
    "                mx = -np.Inf\n",
    "                if index+lookahead >= length:\n",
    "                    #end is within lookahead no more peaks can be found\n",
    "                    break\n",
    "            #else:  #slows shit down this does\n",
    "            #    mn = ahead\n",
    "            #    mnpos = x_axis[np.where(y_axis[index:index+lookahead]==mn)]\n",
    "    \n",
    "    \n",
    "    #Remove the false hit on the first value of the y_axis\n",
    "    try:\n",
    "        if dump[0]:\n",
    "            max_peaks.pop(0)\n",
    "        else:\n",
    "            min_peaks.pop(0)\n",
    "        del dump\n",
    "    except IndexError:\n",
    "        pass\n",
    "        \n",
    "    return [max_peaks, min_peaks]\n",
    "def get_predict_prob(window):\n",
    "    window[:,:] = signal.detrend(RobustScaler().fit_transform(window),axis=0)\n",
    "    f,pxx = signal.welch(window,fs=25,nperseg=len(window),nfft=10000,axis=0)\n",
    "    pxx = np.abs(pxx)\n",
    "    pxx = MinMaxScaler().fit_transform(pxx)\n",
    "    skews = skew(window,axis=0).reshape(3,1)\n",
    "    kurs = kurtosis(window,axis=0).reshape(3,1)\n",
    "    iqrs = np.std(window,axis=0).reshape(3,1)\n",
    "    rps = np.divide(np.trapz(pxx[np.where((f>=.8)&(f<=2.5))[0]],axis=0),np.trapz(pxx,axis=0)).reshape(3,1)\n",
    "    features = np.concatenate([skews,kurs,rps,iqrs],axis=1)\n",
    "    return features\n",
    "\n",
    "def get_rr_value(values):\n",
    "    try:\n",
    "        f, pxx = signal.welch(values,fs=25,nperseg=values.shape[0],nfft=10000,axis=0)\n",
    "        f = f.reshape(-1)\n",
    "        pxx = pxx.reshape(-1,1)\n",
    "        peakind =  peakdetect(pxx[:,0],lookahead=2)\n",
    "        x = []\n",
    "        y = []\n",
    "        for a in peakind[0]:\n",
    "            x.append(a[0])\n",
    "            y.append(a[1])\n",
    "        x = np.array(x)\n",
    "        x = x[f[x]>.8]\n",
    "        x = x[f[x]<2.5]\n",
    "        f = f[x]\n",
    "        pxx = pxx[x,0]\n",
    "        return 60000/(60*f[np.argmax(pxx)])\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "def get_likelihood_custom_seconds(bandpass_filtered_stream,duration,user):\n",
    "    schema2 = StructType([\n",
    "        StructField(\"version\", IntegerType()),\n",
    "        StructField(\"user\", StringType()),\n",
    "        StructField(\"localtime\", TimestampType()),\n",
    "        StructField(\"timestamp\", TimestampType()),\n",
    "        StructField(\"features\", ArrayType(DoubleType())),\n",
    "        StructField(\"rr\", ArrayType(DoubleType())),\n",
    "        StructField(\"quality\", DoubleType()),\n",
    "        StructField(\"activity\", DoubleType()),\n",
    "        StructField(\"start\", TimestampType()),\n",
    "        StructField(\"end\", TimestampType())\n",
    "        \n",
    "    ])\n",
    "    @pandas_udf(schema2, PandasUDFType.GROUPED_MAP)\n",
    "    def ppg_features_compute(key,data):\n",
    "        if data.shape[0]>45:\n",
    "            data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "            rows = []\n",
    "            rows.append(data['user'].loc[0])\n",
    "            rows.append(data['version'].loc[0])\n",
    "            rows.append(data['quality'].loc[0])\n",
    "            rows.append(data['timestamp'].loc[0])\n",
    "            rows.append(data['localtime'].loc[0])\n",
    "            rows.append(np.array([get_rr_value(data['red'].values),\n",
    "                           get_rr_value(data['infrared'].values),\n",
    "                           get_rr_value(data['green'].values)]))\n",
    "\n",
    "            data_ppg = data[['red','infrared','green']]\n",
    "            values = data_ppg.values\n",
    "            feature = get_predict_prob(values)\n",
    "            rows.append(feature.reshape(-1))\n",
    "\n",
    "            data_acl = data[['aclx','acly','aclz']]\n",
    "            values_acl = data_acl.values\n",
    "            acl_std = np.std(values_acl,axis=0)\n",
    "            acl_std = np.sqrt(np.sum(np.square(acl_std)))\n",
    "            rows.append(acl_std)\n",
    "            rows.append(key[2]['start'])\n",
    "            rows.append(key[2]['end'])\n",
    "            return pd.DataFrame([rows],columns=['user','version','quality',\n",
    "                                            'timestamp','localtime',\n",
    "                                            'rr','features','activity','start','end'])\n",
    "\n",
    "        else:\n",
    "            return pd.DataFrame([],columns=['user','version','quality',\n",
    "                                            'timestamp','localtime',\n",
    "                                            'rr','features','activity','start','end'])\n",
    "\n",
    "    ppg_bandpass_filtered = CC.get_stream(bandpass_filtered_stream).drop(*['gyrox','gyroy','gyroz'])\n",
    "    ppg_features = ppg_bandpass_filtered.compute(ppg_features_compute,windowDuration=duration,slideDuration=1,startTime='0 seconds')\n",
    "    schema3 = StructType([\n",
    "        StructField(\"version\", IntegerType()),\n",
    "        StructField(\"user\", StringType()),\n",
    "        StructField(\"localtime\", TimestampType()),\n",
    "        StructField(\"timestamp\", TimestampType()),\n",
    "        StructField(\"likelihood_max\", DoubleType()),\n",
    "        StructField(\"rr\", DoubleType()),\n",
    "        StructField(\"likelihood_max_array\", ArrayType(DoubleType())),\n",
    "        StructField(\"rr_array\", ArrayType(DoubleType())),\n",
    "        StructField(\"activity\", DoubleType()),\n",
    "        StructField(\"start\", TimestampType()),\n",
    "        StructField(\"end\", TimestampType())\n",
    "    ])\n",
    "    import pickle\n",
    "    import warnings\n",
    "    clf = pickle.load(open('/home/jupyter/mullah/cc3/classifier.p','rb'))\n",
    "\n",
    "    def convert_to_array(vals):\n",
    "        return vals.reshape(3,4)\n",
    "\n",
    "    @pandas_udf(schema3, PandasUDFType.GROUPED_MAP)\n",
    "    def ppg_likelihood_compute(key,data):\n",
    "        if data.shape[0]>0:\n",
    "            data['features'] = data['features'].apply(convert_to_array)\n",
    "            acl_features = np.concatenate(list(data['features'])).reshape(-1,3,4)\n",
    "            likelihood = []\n",
    "            for k in range(acl_features.shape[1]):\n",
    "                tmp = np.nan_to_num(acl_features[:,k,:]).reshape(-1,4)\n",
    "                likelihood.append(clf.predict_proba(tmp)[:,1].reshape(-1,1))\n",
    "            likelihood = np.concatenate(likelihood,axis=1)\n",
    "            rrs = data['rr'].values\n",
    "            likelihood_max = []\n",
    "            rr = []\n",
    "            rr_array = []\n",
    "            likelihood_max_array = []\n",
    "            for i in range(likelihood.shape[0]):\n",
    "                a = likelihood[i,:]\n",
    "                likelihood_max_array.append(list(a))\n",
    "                rr_array.append(list(rrs[i]))\n",
    "                likelihood_max.append(np.max(a))\n",
    "                rr.append(rrs[i][np.argmax(a)])\n",
    "            data['likelihood_max'] = likelihood_max\n",
    "            data['rr'] = rr\n",
    "            data['likelihood_max_array'] = likelihood_max_array\n",
    "            data['rr_array'] = rr_array\n",
    "            data.drop(columns=['features','quality'],inplace=True)\n",
    "            return data\n",
    "        else:\n",
    "            return pd.DataFrame([],columns=['user','version','timestamp','localtime','likelihood_max',\n",
    "                                            'rr','activity','likelihood_max_array','rr_array','start','end'])\n",
    "\n",
    "    ppg_likelihood = ppg_features.compute(ppg_likelihood_compute,windowDuration=60*60*12,startTime='0 seconds')\n",
    "    data_ppg = ppg_likelihood.select(*['version','user','localtime','timestamp','likelihood_max','rr',\n",
    "                        'likelihood_max_array','rr_array','activity',F.struct('start', 'end').alias('window')])\n",
    "    rr = CC.get_stream('org.md2k.autosense.ecg.rr.final.pan.tomkins')\n",
    "    ecg = rr.compute_average(windowDuration=duration,startTime='0 seconds',slideDuration='1 seconds').withColumnRenamed('rr','ecg_rr').drop('timestamp',\n",
    "                                                                                                                                        'localtime',\n",
    "                                                                                                                                        'version')\n",
    "    data_final = data_ppg.join(ecg,on=['window','user'],how='left')\n",
    "    return data_final.withColumn('version',F.lit(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for duration in np.arange(2,16,1):\n",
    "    bandpass_filtered_stream = \"org.md2k.motionsensehrv.left.wrist.bandpass.filtered\"\n",
    "#     for user in users:\n",
    "    data_all = get_likelihood_custom_seconds(bandpass_filtered_stream,duration,'-')\n",
    "    save_data(data_all,'ecg.ppg.rr.left-'+str(duration)+'-seconds1')\n",
    "    print(duration,'done')\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all._data.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "for duration in np.arange(2,16,1):\n",
    "    df = CC.get_stream('ecg.ppg.rr.left-'+str(duration)+'-seconds').dropna().toPandas()\n",
    "    final_df = df[(df.rr>300) & (df.rr<1500) & (df.ecg_rr>300) & (df.ecg_rr<1500)]\n",
    "    final_df['likelihood'] = final_df['likelihood_max'].apply(lambda a:np.round(a*100)/100) \n",
    "    final_df['difference'] = final_df.apply(lambda a:np.abs(a['rr']-a['ecg_rr']),axis=1) \n",
    "    all_dfs.append(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(all_dfs,open('../data/rice/all_duration_dfs.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df[(df.rr>300) & (df.rr<1500) & (df.ecg_rr>300) & (df.ecg_rr<1500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['likelihood'] = final_df['likelihood_max'].apply(lambda a:np.round(a*100)/100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['difference'] = final_df.apply(lambda a:np.abs(a['rr']-a['ecg_rr']),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby('likelihood').mean()['difference'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "all_dfs = pickle.load(open('../data/rice/all_duration_dfs.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "plt.rcParams.update({'font.size':20})\n",
    "plt.figure(figsize=(20,10))\n",
    "durations = np.arange(2,16,1)\n",
    "likelihoods = []\n",
    "for i,df in enumerate(all_dfs):\n",
    "#     if i%2==1:\n",
    "#         continue\n",
    "    df = deepcopy(df)\n",
    "    duration = durations[i]\n",
    "    df[str(duration)+'-seconds'] = df['difference']\n",
    "    df.set_index('timestamp',inplace=True)\n",
    "    df = pd.concat([df1 for i,df1 in df.groupby(pd.Grouper(freq='60S')) if df1.shape[0]>0 and np.percentile(df1['likelihood_max'],80)>.5])    \n",
    "    df['likelihood'] = df['likelihood_max'].apply(lambda a:np.round((a*99.99)//5))\n",
    "    if i==6:\n",
    "        likelihoods.extend(list(df['likelihood']*20))\n",
    "    results = df.groupby('likelihood',as_index=False).mean()[['likelihood',str(duration)+'-seconds']]\n",
    "    plt.plot(results['likelihood']*20,results[str(duration)+'-seconds'],linestyle='dashdot',marker='o',label=str(duration)+'-seconds',linewidth=3)\n",
    "ax1 = plt.gca()\n",
    "ax = ax1.twinx()\n",
    "ax.hist(likelihoods,200,alpha=.25,density=True,edgecolor='red',linewidth=2)\n",
    "ax.set_ylabel('Density of Yield in Different Ranges of signal Quality',color='red')\n",
    "ax.tick_params(axis='y', labelcolor='red')\n",
    "ax1.legend(ncol=5,loc='upper right')\n",
    "labels = [str(\"{:.2f}\".format(i/20))+'-'+str(\"{:.2f}\".format(i/20+.05))  for i in np.arange(0,20,1)]\n",
    "# labels[-1] = '==1.00'\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.set_xticks(np.arange(0,20,1)*20)\n",
    "ax1.tick_params(axis='y', labelcolor='green')\n",
    "ax1.set_ylabel('Mean Absolute Difference in milliseconds',color='green')\n",
    "for tick in ax1.get_xticklabels():\n",
    "    tick.set_rotation(60)\n",
    "ax1.set_xlabel('Different Ranges of Signal Quality Likelihood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_dfs[1]\n",
    "import pandas  as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('timestamp',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "final_df = pd.concat([df1 for i,df1 in df.groupby(pd.Grouper(freq='60S')) if df1.shape[0]>0 and np.percentile(df1['likelihood_max'],80)>.5])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291941, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155034, 12)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([27830., 14158., 11584., 11396., 10915., 11162., 11766., 14310.,\n",
       "        14627., 27286.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(final_df['likelihood_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3 High Performance",
   "language": "python",
   "name": "cc3_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
