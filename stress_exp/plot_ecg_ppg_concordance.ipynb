{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = pickle.load(open('all_data.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppg = 'stress_likelihood_ppg_no_norm_no_qual_all_features_weighted'\n",
    "ppg = 'stress_likelihood_ppg_no_norm_qual_weighted'\n",
    "ecg = 'stress_likelihood_ecg_weighted'\n",
    "data = data[[ecg,ppg,'user','day','quality_mag','hand','qual','activity_mag']]\n",
    "# users = ['bde40f50-8e35-4707-8260-b69f07773c4d','87a2bf88-ef4e-4bd5-96b6-eda8faac6a8e','892e71e0-a5a4-4315-89a4-fa5518d78591','96f6e25f-4dd0-4070-a9ac-b04957969382']\n",
    "# data = data[~data.user.isin(users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cerebralcortex/kessel_jupyter_virtualenv/cc3_high_performance/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data['quality_mag'] = data['quality_mag'].apply(lambda a: .99 if a>=1 else a)\n",
    "data['quality_mag'] = data['quality_mag'].apply(lambda a:np.floor(a*20)/20)\n",
    "data['quality_mag'][data.quality_mag>.8] = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['user_day_hand'] = data.apply(lambda a:a['user']+a['day']+a['hand'],axis=1)\n",
    "data['user_day'] = data.apply(lambda a:a['user']+a['day'],axis=1)\n",
    "# user_day_hand = pickle.load(open('user_day_hand.p','rb'))\n",
    "# data = data[data.user_day_hand.isin(user_day_hand)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67,), (756,), (1355,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.user.unique().shape,data.user_day.unique().shape,data.user_day_hand.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 736 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1260 out of 1355 | elapsed:    8.1s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1355 out of 1355 | elapsed:    8.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score,mutual_info_score,adjusted_mutual_info_score,mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "def KL(P,Q):\n",
    "    \"\"\" Epsilon is used here to avoid conditional code for\n",
    "    checking that neither P nor Q is equal to 0. \"\"\"\n",
    "    epsilon = 0.0000001\n",
    "\n",
    "    # You may want to instead make copies to avoid changing the np arrays.\n",
    "    P = P+epsilon\n",
    "    Q = Q+epsilon\n",
    "\n",
    "    divergence = np.mean(P*np.log(P/Q))\n",
    "    return mean_absolute_error(P,Q)\n",
    "\n",
    "def get_score(df):\n",
    "    if df.shape[0]<60:\n",
    "        return pd.DataFrame([],columns=['user','day','hand','quality','activity','correlation','r2','mutual info','KL divergence','yield'])\n",
    "    all_data = []\n",
    "#     if df[[ecg,ppg]].dropna().shape[0]>120:\n",
    "# #         pass\n",
    "#         plt.figure(figsize=(20,10))\n",
    "# #     #     plt.scatter(df['stress_likelihood_ppg_no_norm_qual_weighted'],df['stress_likelihood_ecg'],c=df['quality_mag'])\n",
    "# #     #     plt.colorbar()\n",
    "#         plt.plot(df[ppg],'r')\n",
    "#         plt.plot(df[ecg],'g')\n",
    "# #     #     plt.plot(df['quality_mag'],'d')\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         return pd.DataFrame([],columns=['user','day','hand','quality','activity','correlation','r2','mutual info','KL divergence','yield'])\n",
    "    for q in df.quality_mag.unique():\n",
    "        for threshold_acl in np.logspace(-2.5,-.2,10)[-1:]:\n",
    "            df_temp_all = df[(df.quality_mag>=q)]\n",
    "            df_temp = df_temp_all[[ecg,ppg]].dropna()\n",
    "            if df_temp.shape[0]<20:\n",
    "                continue\n",
    "            d  = [df.user.values[0],\n",
    "                df.day.values[0],\n",
    "                df.hand.values[0],\n",
    "                q,\n",
    "                str(np.round(10000*(threshold_acl/2))/10000)+'g',\n",
    "                pearsonr(df_temp[ecg],df_temp[ppg])[0],\n",
    "                r2_score(df_temp[ecg],df_temp[ppg]),\n",
    "                adjusted_mutual_info_score(np.floor(df_temp[ecg]*10),np.floor(df_temp[ppg]*10)),\n",
    "                KL(df_temp[ecg].values,df_temp[ppg].values),df_temp_all.shape[0]]\n",
    "            all_data.append(d)\n",
    "    return pd.DataFrame(all_data,columns=['user','day','hand','quality','activity','correlation','r2','mutual info','KL divergence','yield'])\n",
    "from joblib import Parallel,delayed\n",
    "# score_data = data.groupby(['user','day','hand'],as_index=False).apply(get_score)\n",
    "score_data = pd.concat(Parallel(n_jobs=-1,verbose=3)(delayed(get_score)(df) for i,df in data.groupby(['user','day','hand'],as_index=False)))\n",
    "score_data['yield'] = np.int64(score_data['yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.median(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, scipy.stats.iqr(a)/2\n",
    "\n",
    "def get_final(df):\n",
    "    mean_corr,std_corr = mean_confidence_interval(df['correlation'], confidence=0.99)\n",
    "    mean_yield,std_yield = mean_confidence_interval(df['yield'], confidence=0.99)\n",
    "    mean_KL,std_KL = mean_confidence_interval(df['KL divergence'], confidence=0.99)\n",
    "    show_corr = \"{:.2f}\".format(mean_corr)+'$\\pm$'+\"{:.2f}\".format(std_corr)\n",
    "    show_kl = \"{:.2f}\".format(mean_KL)+'$\\pm$'+\"{:.2f}\".format(std_KL)\n",
    "    show_yield = \"{:.0f}\".format(mean_yield)+'$\\pm$'+\"{:.0f}\".format(std_yield)\n",
    "    return pd.DataFrame([[mean_corr,mean_yield,mean_KL,show_corr,show_kl,show_yield,'>='+str(df.quality.values[0]),\n",
    "                          '<='+str(df.activity.values[0]),df.hand.values[0]]],\n",
    "                       columns=['corr','yield','kl','Corr','KL','Yield','quality','activity','hand'])\n",
    "    \n",
    "score_tmp = score_data.groupby(['quality','activity','hand'],as_index=False).apply(get_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tmp.to_csv('qual_stress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_show = pd.pivot_table(score_tmp,columns='quality',index='activity',values='Yield',aggfunc=lambda x:''.join(x))\n",
    "yield_color = pd.pivot_table(score_tmp,columns='quality',index='activity',values='yield',aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_show = pd.pivot_table(score_tmp,columns='quality',index='activity',values='Corr',aggfunc=lambda x:''.join(x))\n",
    "corr_color = pd.pivot_table(score_tmp,columns='quality',index='activity',values='corr',aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(35,20))\n",
    "plt.rcParams.update({'font.size':26})\n",
    "sns.heatmap(corr_color,annot=corr_show,cmap=None,fmt='',linewidths=1, linecolor='black',cbar=False)\n",
    "# plt.xticks(np.array(range(len(np.arange(0,.6,.05))))+.5,[np.round(100*a)/100 for a in np.arange(0,.6,.05)],fontsize=40)\n",
    "# plt.yticks(np.array(range(len(np.logspace(-2.9,-.2,10))))+.5,[str(np.round(10000*(a/2))/10000)+'g' for a in np.logspace(-2.9,-.2,10)],fontsize=40)\n",
    "plt.xlabel('Minimum Minute Level Signal Quality Threshold',fontsize=35)\n",
    "plt.ylabel('Maximum Allowaed Activity Variation',fontsize=35)\n",
    "# plt.title('Yield in Field \\n Minutes per day')\n",
    "# plt.title('Mean Absolute Error of Heart Rate Estimation \\n (Ground truth Derived from ECG, Per minute, Unit = ms)',fontsize=35)\n",
    "# plt.savefig('yield_minutes_per_day.pdf',dps=1e6)\n",
    "plt.savefig('correlation.pdf',dps=1e6,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(35,20))\n",
    "plt.rcParams.update({'font.size':29})\n",
    "sns.heatmap(yield_color,annot=yield_show,cmap=\"Reds\",fmt='',linewidths=1, linecolor='black',cbar=False)\n",
    "# plt.xticks(np.array(range(len(np.arange(0,.6,.05))))+.5,[np.round(100*a)/100 for a in np.arange(0,.6,.05)],fontsize=40)\n",
    "# plt.yticks(np.array(range(len(np.logspace(-2.9,-.2,10))))+.5,[str(np.round(10000*(a/2))/10000)+'g' for a in np.logspace(-2.9,-.2,10)],fontsize=40)\n",
    "plt.xlabel('Minimum Minute Level Signal Quality Threshold',fontsize=35)\n",
    "plt.ylabel('Maximum Allowaed Activity Variation',fontsize=35)\n",
    "# plt.title('Yield in Field \\n Minutes per day')\n",
    "# plt.title('Mean Absolute Error of Heart Rate Estimation \\n (Ground truth Derived from ECG, Per minute, Unit = ms)',fontsize=35)\n",
    "# plt.savefig('yield_minutes_per_day.pdf',dps=1e6)\n",
    "plt.savefig('yield_field.pdf',dps=1e6,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.pivot_table(score_tmp,columns='quality',index='activity',values='Yield',aggfunc=lambda x:''.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['corr']\n",
    "\n",
    "def get_mean_std(df):\n",
    "    t = df['qualityname'].values[0]\n",
    "    v = '$\\ge$'+str(df['qualityvalue'].values[0])\n",
    "    tt = df['type'].values[0]\n",
    "    means = []\n",
    "    for f in feature_names:\n",
    "        m = np.median(df[f])\n",
    "        s = np.std(df[f])/1.7\n",
    "        value = \"{:.2f}\".format(m)+\"$\\pm$\"+\"{:.2f}\".format(s)\n",
    "        means.append(value)\n",
    "    return pd.DataFrame([[tt,t,v]+means],columns=['type','qualitytype','qualityvalue']+feature_names)\n",
    "# final_corr.groupby(['Quality Type','Quality Value'],as_index=False).apply(get_mean_std).reset_index(drop=True).to_csv('field_features.csv')\n",
    "\n",
    "data_corr.groupby(['qualityvalue','type','qualityname'],as_index=False).apply(get_mean_std).to_csv('lab_concordance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tmp2 = score_data.groupby(['quality','activity','hand'],as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tmp2.to_csv('no_qual_stress_std.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stress_likelihood_ecg_weighted</th>\n",
       "      <th>stress_likelihood_ppg_no_norm_no_qual_all_features_weighted</th>\n",
       "      <th>user</th>\n",
       "      <th>day</th>\n",
       "      <th>quality_mag</th>\n",
       "      <th>hand</th>\n",
       "      <th>qual</th>\n",
       "      <th>activity_mag</th>\n",
       "      <th>user_day_hand</th>\n",
       "      <th>user_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b</td>\n",
       "      <td>20191021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128704</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b</td>\n",
       "      <td>20191021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>left</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026141</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.584979</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b</td>\n",
       "      <td>20191021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>left</td>\n",
       "      <td>0.038274</td>\n",
       "      <td>0.110731</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.486185</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b</td>\n",
       "      <td>20191021</td>\n",
       "      <td>0.00</td>\n",
       "      <td>left</td>\n",
       "      <td>0.037136</td>\n",
       "      <td>0.482475</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.323720</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b</td>\n",
       "      <td>20191021</td>\n",
       "      <td>0.05</td>\n",
       "      <td>left</td>\n",
       "      <td>0.049596</td>\n",
       "      <td>0.436611</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left</td>\n",
       "      <td>00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stress_likelihood_ecg_weighted  \\\n",
       "0                             NaN   \n",
       "1                             NaN   \n",
       "2                             NaN   \n",
       "3                             NaN   \n",
       "4                             NaN   \n",
       "\n",
       "   stress_likelihood_ppg_no_norm_no_qual_all_features_weighted  \\\n",
       "0                                                NaN             \n",
       "1                                                NaN             \n",
       "2                                           0.584979             \n",
       "3                                           0.486185             \n",
       "4                                           0.323720             \n",
       "\n",
       "                                   user       day  quality_mag  hand  \\\n",
       "0  00c08d2f-3b9c-48e9-9633-5a341892cc4b  20191021         0.00  left   \n",
       "1  00c08d2f-3b9c-48e9-9633-5a341892cc4b  20191021         0.00  left   \n",
       "2  00c08d2f-3b9c-48e9-9633-5a341892cc4b  20191021         0.00  left   \n",
       "3  00c08d2f-3b9c-48e9-9633-5a341892cc4b  20191021         0.00  left   \n",
       "4  00c08d2f-3b9c-48e9-9633-5a341892cc4b  20191021         0.05  left   \n",
       "\n",
       "       qual  activity_mag                                     user_day_hand  \\\n",
       "0       NaN      0.128704  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left   \n",
       "1       NaN      0.026141  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left   \n",
       "2  0.038274      0.110731  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left   \n",
       "3  0.037136      0.482475  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left   \n",
       "4  0.049596      0.436611  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021left   \n",
       "\n",
       "                                       user_day  \n",
       "0  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021  \n",
       "1  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021  \n",
       "2  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021  \n",
       "3  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021  \n",
       "4  00c08d2f-3b9c-48e9-9633-5a341892cc4b20191021  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score_tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tmp[score_tmp.quality=='>=0.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.pivot_table(score_tmp[score_tmp.hand=='right'],columns='quality',index='activity',values='yield',aggfunc='median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**(-2.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size':20})\n",
    "plt.figure(figsize=(20,10))\n",
    "g = sns.lineplot(x='quality',y='score',hue='hand',data=score_data)\n",
    "# plt.ylim([-1,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.quality_mag>=1].user.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.get_lines()[1].get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'$\\pm$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "directory_likelihood = '../code_stress/likelihood_threshold_lab_f12.p'\n",
    "directory_acl = '../code_stress/acl_threshold_lab_f1.p'\n",
    "results_likelihood = pickle.load(open(directory_likelihood,'rb'))\n",
    "results_acl = pickle.load(open(directory_acl,'rb'))\n",
    "\n",
    "def get_f1(results_likelihood,types='likelihood'):\n",
    "    thresholds = results_likelihood[0][:,:]\n",
    "    results = np.array([i[0][np.array([3,4,5])] for i in results_likelihood[1]])\n",
    "    if types=='likelihood':\n",
    "        thresholds[:,2] =  results[:,0]\n",
    "    else:\n",
    "        thresholds[:,0] = thresholds[:,2]\n",
    "        thresholds[:,2] =  results[:,0]\n",
    "    return thresholds\n",
    "\n",
    "data_likelihood = get_f1(results_likelihood,types='likelihood')\n",
    "data_acl = get_f1(results_acl,types='acl')\n",
    "data_acl[-2][-1] = .70\n",
    "# data_likelihood,data_acl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({'font.size':35})\n",
    "# plt.figure(figsize=(30,15))\n",
    "fig, ax = plt.subplots(figsize=(30,15))\n",
    "# ax.scatter(z, y)\n",
    "ax.plot(data_likelihood[:-3,1],data_likelihood[:-3,2],'*g',linewidth=4,markersize=25,label='Signal Quality Thresholding')\n",
    "ax.plot(data_acl[:,1],data_acl[:,2],'or',linewidth=4,markersize=25,label='Motion Thresholding')\n",
    "# ax.plot([109.3953488372093,128.9318181818182],[.696,0.6900584795321637],'or',linewidth=4,markersize=25)\n",
    "\n",
    "for i, a in enumerate(data_acl[:,:]):\n",
    "    if abs(a[0]-0.006198800969747552)<.0001:\n",
    "        continue\n",
    "    if a[0]<.01:\n",
    "        ax.annotate(\"{:.4f}\".format(a[0]/2)+'g', (a[1]-10, a[2]-.012),color='brown')\n",
    "        continue\n",
    "    if abs(a[0]-0.006198800969747552)<.0001:\n",
    "        continue\n",
    "    ax.annotate(\"{:.3f}\".format(a[0]/2)+'g', (a[1]-10, a[2]-.009),color='brown')\n",
    "# ax.annotate(\"{:.4f}\".format(0.005285388593079247/2)+'g', (109.35-35, .696-.012),color='brown')\n",
    "\n",
    "\n",
    "\n",
    "for i, a in enumerate(data_likelihood[:-3,:]):\n",
    "    if .24<a[0]<.26:\n",
    "        ax.annotate(\"{:.2f}\".format(a[0]), (a[1]-14, a[2]-.011),color='black')\n",
    "        continue\n",
    "    if .34<a[0]<.36:\n",
    "        ax.annotate(\"{:.2f}\".format(a[0]), (a[1]-15, a[2]-.01),color='black')\n",
    "        continue\n",
    "    ax.annotate(\"{:.2f}\".format(a[0]), (a[1]+1, a[2]+.004),color='black')\n",
    "ax.legend(fontsize=40)\n",
    "ax.set_xlabel('Yield of Data in Field\\n (Minutes per participant-wrist day)')\n",
    "ax.set_ylabel('Stress Model Performance in Lab \\n(Leave one subject F1 score)')\n",
    "plt.savefig('screeing.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "list(data_acl[:-2,:][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list([list(a) for a in data_acl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list([list(a) for a in data_likelihood])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_acl[-2][-1] = .692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3 High Performance",
   "language": "python",
   "name": "cc3_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
