{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# data = pickle.load(open('../data/leftppgecg.p','rb'))\n",
    "directory = '../data_users/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(directory+'ecg_ppg_25_left.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory+'ecg_ppg_25_left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data_users/ecg_ppg_25_left/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19842, 16) 0c726695-f016-4019-9aab-c292298ee10c.p (7430, 16)\n"
     ]
    }
   ],
   "source": [
    "for d in os.listdir(directory):\n",
    "    if d[-1]!='p' or d not in ['0c726695-f016-4019-9aab-c292298ee10c.p']:\n",
    "        continue\n",
    "    data = pickle.load(open(directory+d,'rb'))\n",
    "    print(data.shape,d,data.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mullah\\AppData\\Local\\Continuum\\miniconda3\\envs\\rr\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import iqr\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def weighted_avg_and_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    return average, math.sqrt(variance)\n",
    "\n",
    "def get_rr_features(a):\n",
    "    return np.array([np.var(a),iqr(a),np.mean(a),np.median(a),np.percentile(a,80),np.percentile(a,20),60000/np.median(a)])\n",
    "\n",
    "def get_quality_features(a):\n",
    "    features = [np.mean(a),np.median(a),\n",
    "                np.percentile(a,75),np.percentile(a,25),\n",
    "                len(np.where(a>0)[0])/60,len(np.where(a>.25)[0])/60,len(np.where(a>.5)[0])/60,len(np.where(a>.75)[0])/60]\n",
    "    return np.array(features)\n",
    "\n",
    "def get_daywise(data):\n",
    "    return [a for i,a in data.groupby(['user','day']) if a.dropna().shape[0]>60]\n",
    "\n",
    "def parse_day_data(data_day):\n",
    "    data_day = data_day.sort_values('ltime').reset_index(drop=True)\n",
    "    data_day['likelihood_max_array'] = data_day['likelihood_max_array'].apply(lambda a:np.squeeze(a))\n",
    "    data_day['likelihood'] = data_day['likelihood_max_array'].apply(lambda a:np.max(a,axis=1))\n",
    "    data_day['likelihood_ind'] = data_day['likelihood_max_array'].apply(lambda a:np.argmax(a,axis=1))\n",
    "    data_day['rr_array'] = data_day['rr_array'].apply(lambda a:np.squeeze(a))\n",
    "    data_day['time'] = data_day['ltime'].apply(lambda a:datetime.timestamp(a))\n",
    "    indexes = data_day['likelihood_ind'].values\n",
    "    rr_arrays = data_day['rr_array'].values\n",
    "    rrs = []\n",
    "    for i,rr in enumerate(rr_arrays):\n",
    "        index = indexes[i]\n",
    "        frr = np.squeeze(np.array([rr[i,index[i]] for i in range(rr.shape[0])]))\n",
    "        rrs.append(frr)\n",
    "    data_day['rr'] = rrs\n",
    "    data_day['rr_col'] = data_day.apply(lambda a: np.vstack([np.squeeze(a['rr']),np.squeeze(a['likelihood'])]).T,\n",
    "                     axis=1)\n",
    "    return data_day\n",
    "\n",
    "def remove_3sd(heart_rate_window):\n",
    "    temp = deepcopy(heart_rate_window)\n",
    "    try:\n",
    "        r,tt = weighted_avg_and_std(heart_rate_window[heart_rate_window[:,1]>.25,0],heart_rate_window[heart_rate_window[:,1]>.25,1])\n",
    "        index = np.where((heart_rate_window[:,0]<r+3*tt)&(heart_rate_window[:,0]>r-3*tt))[0]\n",
    "        heart_rate_window = heart_rate_window[index]\n",
    "    except:\n",
    "        pass\n",
    "    if heart_rate_window.shape[0]>10:\n",
    "        return [heart_rate_window,'Available']\n",
    "    else:\n",
    "        return [temp,'Not Available']\n",
    "\n",
    "    \n",
    "def parse_for_features(data_day):\n",
    "    data_day['rr_col'] = data_day['rr_col'].apply(lambda a:a[np.where((a[:,1]>.05)&(a[:,0]>300)&(a[:,0]<1500))[0]])\n",
    "    data_day['rr_col'] = data_day['rr_col'].apply(lambda a:remove_3sd(a))\n",
    "    data_day['indicator'] = data_day['rr_col'].apply(lambda a:a[1])\n",
    "    data_day['rr_col'] = data_day['rr_col'].apply(lambda a:a[0])\n",
    "    data_day['likelihood'] = data_day['rr_col'].apply(lambda a:a[:,1])\n",
    "    data_day['rr'] = data_day['rr_col'].apply(lambda a:a[:,0])\n",
    "    data_day['rr_features'] = data_day['rr'].apply(lambda a:get_rr_features(a))\n",
    "    data_day['quality_features'] = data_day['likelihood'].apply(lambda a:get_quality_features(a))\n",
    "    data_day['quality_mag'] = data_day['quality_features'].apply(lambda a:np.sqrt(np.sum(np.square(a))/8))\n",
    "    return data_day\n",
    "\n",
    "def get_stress(data_day,stress_model):\n",
    "    feature_matrix = np.array(list(a['rr_features'].values))\n",
    "    quals1 = np.array(list(a['quality_mag'].values))\n",
    "    for i in range(feature_matrix.shape[1]):\n",
    "        m,s = weighted_avg_and_std(feature_matrix[:,i], quals1)\n",
    "        feature_matrix[:,i]  = (feature_matrix[:,i] - m)/s\n",
    "    stress_likelihood = stress_model.predict_proba(feature_matrix)[:,1]\n",
    "    data_day['stress_likelihood1'] = stress_likelihood\n",
    "    return data_day\n",
    "\n",
    "def get_corr(data_day):\n",
    "    data_day = data_day.dropna()\n",
    "    data_day['quality_mag_1'] = data_day['quality_mag'].apply(lambda a:np.round(100*a)//10)\n",
    "    all_corr = np.array([np.array([df['quality_mag_1'].values[0],\n",
    "                          pearsonr(df['stress_likelihood_ecg'].values,df['stress_likelihood'].values)[0],\n",
    "                          pearsonr(df['stress_likelihood_ecg'].values,df['stress_likelihood1'].values)[0],\n",
    "                          pearsonr(df['stress_likelihood'].values,df['stress_likelihood1'].values)[0]]) for i,df in data_day.groupby(['quality_mag_1']) if df.shape[0]>20])\n",
    "    return all_corr\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "data_all = get_daywise(data)\n",
    "a = data_all[0]\n",
    "a = parse_day_data(a)\n",
    "a = parse_for_features(a)\n",
    "stress_model = pickle.load(open('../models/stress.p','rb'))\n",
    "a = get_stress(a,stress_model)\n",
    "all_corr = get_corr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        , -0.26665371, -0.29522191,  0.68420255],\n",
       "       [ 3.        ,  0.03016076,  0.01954035,  0.67383293],\n",
       "       [ 4.        , -0.0204236 ,  0.01441313,  0.74303852],\n",
       "       [ 5.        ,  0.41676042,  0.60915975,  0.21845877]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_mag</th>\n",
       "      <th>stress_likelihood</th>\n",
       "      <th>stress_likelihood_ecg</th>\n",
       "      <th>stress_likelihood1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370911</td>\n",
       "      <td>0.201899</td>\n",
       "      <td>0.033323</td>\n",
       "      <td>0.084747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.361321</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.140392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.328478</td>\n",
       "      <td>0.171370</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.172813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.424161</td>\n",
       "      <td>0.423396</td>\n",
       "      <td>0.029207</td>\n",
       "      <td>0.161418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.395056</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>0.067507</td>\n",
       "      <td>0.097283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>0.594561</td>\n",
       "      <td>0.480980</td>\n",
       "      <td>0.114348</td>\n",
       "      <td>0.157681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.666574</td>\n",
       "      <td>0.311742</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>0.175355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.553743</td>\n",
       "      <td>0.521317</td>\n",
       "      <td>0.126435</td>\n",
       "      <td>0.105184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.644743</td>\n",
       "      <td>0.470700</td>\n",
       "      <td>0.903775</td>\n",
       "      <td>0.211244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.572475</td>\n",
       "      <td>0.411875</td>\n",
       "      <td>0.644204</td>\n",
       "      <td>0.136830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     quality_mag  stress_likelihood  stress_likelihood_ecg  stress_likelihood1\n",
       "0       0.370911           0.201899               0.033323            0.084747\n",
       "1       0.361321           0.006499               0.021960            0.140392\n",
       "2       0.328478           0.171370               0.040796            0.172813\n",
       "3       0.424161           0.423396               0.029207            0.161418\n",
       "4       0.395056           0.017021               0.067507            0.097283\n",
       "..           ...                ...                    ...                 ...\n",
       "706     0.594561           0.480980               0.114348            0.157681\n",
       "707     0.666574           0.311742               0.108311            0.175355\n",
       "708     0.553743           0.521317               0.126435            0.105184\n",
       "709     0.644743           0.470700               0.903775            0.211244\n",
       "710     0.572475           0.411875               0.644204            0.136830\n",
       "\n",
       "[501 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[['quality_mag','stress_likelihood','stress_likelihood_ecg','stress_likelihood1']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['time'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
