{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# data = pickle.load(open('../data/leftppgecg.p','rb'))\n",
    "directory = '../data_users/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(directory+'ecg_ppg_25_left.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory+'ecg_ppg_25_left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data_users/ecg_ppg_25_left/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19842, 16) 0c726695-f016-4019-9aab-c292298ee10c.p (7430, 16)\n"
     ]
    }
   ],
   "source": [
    "for d in os.listdir(directory):\n",
    "    if d[-1]!='p' or d not in ['0c726695-f016-4019-9aab-c292298ee10c.p']:\n",
    "        continue\n",
    "    data = pickle.load(open(directory+d,'rb'))\n",
    "    print(data.shape,d,data.dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "def weighted_avg_and_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    return average, math.sqrt(variance)\n",
    "\n",
    "def get_rr_features(a):\n",
    "    return np.array([np.var(a),iqr(a),np.mean(a),np.median(a),np.percentile(a,80),np.percentile(a,20),60000/np.median(a)])\n",
    "\n",
    "def get_quality_features(a):\n",
    "    features = [np.mean(a),np.median(a),\n",
    "                np.percentile(a,75),np.percentile(a,25),\n",
    "                len(np.where(a>0)[0])/60,len(np.where(a>.25)[0])/60,len(np.where(a>.5)[0])/60,len(np.where(a>.75)[0])/60]\n",
    "    return np.array(features)\n",
    "\n",
    "def get_daywise(data):\n",
    "    return [a for i,a in data.groupby(['user','day']) if a.dropna().shape[0]>60]\n",
    "\n",
    "def parse_day_data(data_day):\n",
    "    data_day = data_day.sort_values('ltime').reset_index(drop=True)\n",
    "    data_day['likelihood_max_array'] = data_day['likelihood_max_array'].apply(lambda a:np.squeeze(a))\n",
    "    data_day['likelihood'] = data_day['likelihood_max_array'].apply(lambda a:np.max(a,axis=1))\n",
    "    data_day['likelihood_ind'] = data_day['likelihood_max_array'].apply(lambda a:np.argmax(a,axis=1))\n",
    "    data_day['rr_array'] = data_day['rr_array'].apply(lambda a:np.squeeze(a))\n",
    "    data_day['time'] = data_day['ltime'].apply(lambda a:datetime.timestamp(a))\n",
    "    indexes = data_day['likelihood_ind'].values\n",
    "    rr_arrays = data_day['rr_array'].values\n",
    "    rrs = []\n",
    "    for i,rr in enumerate(rr_arrays):\n",
    "        index = indexes[i]\n",
    "        frr = np.squeeze(np.array([rr[i,index[i]] for i in range(rr.shape[0])]))\n",
    "        rrs.append(frr)\n",
    "    data_day['rr'] = rrs\n",
    "    data_day['rr_col'] = data_day.apply(lambda a: np.vstack([np.squeeze(a['rr']),np.squeeze(a['likelihood'])]).T,\n",
    "                     axis=1)\n",
    "    return data_day\n",
    "\n",
    "def remove_3sd(heart_rate_window):\n",
    "    temp = deepcopy(heart_rate_window)\n",
    "    try:\n",
    "        r,tt = weighted_avg_and_std(heart_rate_window[heart_rate_window[:,1]>.25,0],heart_rate_window[heart_rate_window[:,1]>.25,1])\n",
    "        index = np.where((heart_rate_window[:,0]<r+3*tt)&(heart_rate_window[:,0]>r-3*tt))[0]\n",
    "        heart_rate_window = heart_rate_window[index]\n",
    "    except:\n",
    "        pass\n",
    "    if heart_rate_window.shape[0]>10:\n",
    "        return [heart_rate_window,'Available']\n",
    "    else:\n",
    "        return [temp,'Not Available']\n",
    "\n",
    "    \n",
    "def parse_for_features(data_day):\n",
    "    data_day['rr_col'] = data_day['rr_col'].apply(lambda a:a[np.where((a[:,1]>.05)&(a[:,0]>300)&(a[:,0]<1500))[0]])\n",
    "    data_day['rr_col'] = data_day['rr_col'].apply(lambda a:remove_3sd(a))\n",
    "    data_day['indicator'] = data_day['rr_col'].apply(lambda a:a[1])\n",
    "    data_day['rr_col'] = data_day['rr_col'].apply(lambda a:a[0])\n",
    "    data_day['likelihood'] = data_day['rr_col'].apply(lambda a:a[:,1])\n",
    "    data_day['rr'] = data_day['rr_col'].apply(lambda a:a[:,0])\n",
    "    data_day['rr_features'] = data_day['rr'].apply(lambda a:get_rr_features(a))\n",
    "    data_day['quality_features'] = data_day['likelihood'].apply(lambda a:get_quality_features(a))\n",
    "    data_day['quality_mag'] = data_day['quality_features'].apply(lambda a:np.sqrt(np.sum(np.square(a))/8))\n",
    "    return data_day\n",
    "\n",
    "data_all = get_daywise(data)\n",
    "a = data_all[0]\n",
    "a = parse_day_data(a)\n",
    "a = parse_for_features(a)\n",
    "stress_model = pickle.load(open('../models/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.33755972, 0.29083333, 0.52175   , 0.14283333, 0.66666667,\n",
       "        0.35      , 0.2       , 0.05      ]),\n",
       " 0.3709109498754514)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['quality_features'].loc[0],a['quality_mag'].loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829, 7)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(a['rr_features'].values)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['time'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
