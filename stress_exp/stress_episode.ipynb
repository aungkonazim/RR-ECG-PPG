{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  67 out of  94 | elapsed:  9.2min remaining:  3.7min\n",
      "[Parallel(n_jobs=30)]: Done  94 out of  94 | elapsed: 13.2min finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.window import _flex_binary_moment, _Rolling_and_Expanding\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pb\n",
    "import GPy \n",
    "# %pylab inline\n",
    "def get_predictions(X,Y,error):\n",
    "    X = (X - np.mean(X))/np.std(X)\n",
    "    mm = np.mean(Y)\n",
    "    ss = np.std(Y)\n",
    "    Y = (Y-np.mean(Y))/ss\n",
    "    kern =  GPy.kern.RBF(input_dim=1) + GPy.kern.MLP(1) \n",
    "    Y_meta = {'output_index':np.arange(len(Y))[:,None]}\n",
    "    m = GPy.models.GPHeteroscedasticRegression(X[:,None],Y[:,None],kern,Y_metadata=Y_meta)\n",
    "    m['.*het_Gauss.variance'] = np.abs(error)[:,None] #Set the noise parameters to the error in Y\n",
    "    m.het_Gauss.variance.fix() #We can fix the noise term, since we already know it\n",
    "    m.optimize()\n",
    "    preds,varss  = m.predict(m.X,full_cov=False,Y_metadata=None,kern=None,likelihood=None,include_likelihood=False)\n",
    "    return preds*ss+mm,varss\n",
    "\n",
    "def weighted_mean(self, weights, **kwargs):\n",
    "    weights = self._shallow_copy(weights)\n",
    "    window = self._get_window(weights)\n",
    "\n",
    "    def _get_weighted_mean(X, Y):\n",
    "        X = X.astype('float64')\n",
    "        Y = Y.astype('float64')\n",
    "        sum_f = lambda x: x.rolling(window, self.min_periods, center=self.center).sum(**kwargs)\n",
    "        return sum_f(X * Y) / sum_f(Y)\n",
    "\n",
    "    return _flex_binary_moment(self._selected_obj, weights._selected_obj,\n",
    "                               _get_weighted_mean, pairwise=True)\n",
    "\n",
    "def dump_data(directory_ema,directory1,directory2,f):\n",
    "    if f not in os.listdir(directory_ema):\n",
    "        return 0\n",
    "    data = pickle.load(open(directory1+f,'rb'))\n",
    "    a = data[0]\n",
    "    this_participant = []\n",
    "    stress_all = a[['time','ltime','user','stress_likelihood_ppg','quality_mag','day','activity','hand','rr_weighted_features']].dropna()\n",
    "    stress_all['hr'] = stress_all['rr_weighted_features'].apply(lambda a:a[-5])\n",
    "    stress_days = [a for i,a in stress_all.groupby(['hand','day'],as_index=False) if a.shape[0]>180]\n",
    "    _Rolling_and_Expanding.weighted_mean = weighted_mean\n",
    "    for a in stress_days:\n",
    "        a = a.dropna().sort_values('time').reset_index(drop=False)\n",
    "        a['stress_likelihood_ppg_qual'] = a['stress_likelihood_ppg'].rolling(window = 7).weighted_mean(a['quality_mag'])\n",
    "        a['qual'] = a['quality_mag'].rolling(window = 7).weighted_mean(a['quality_mag'])\n",
    "        a['hr'] = a['hr'].rolling(window = 7).weighted_mean(a['quality_mag'])\n",
    "        a = a.dropna()\n",
    "        preds,varss = get_predictions(a['time'].values,a['stress_likelihood_ppg_qual'].values,(1.1-a['quality_mag'].values)/2)\n",
    "        a['stress_final'] = preds\n",
    "#         print(preds)\n",
    "#         plt.plot(a['ltime'],a['stress_final'])\n",
    "#         plt.show()\n",
    "        this_participant.append(a)\n",
    "        print(a.shape)\n",
    "    data = pd.concat(this_participant).dropna().sort_values('time').reset_index(drop=True)\n",
    "#     left_data = data[data.hand=='left']\n",
    "#     right_data = data[data.hand=='right']\n",
    "#     left_daywise_data = [a for i,a in left_data.groupby(['day'],as_index=False) if a.shape[0]>180]\n",
    "#     participant_mean = np.average(data['stress_likelihood_ppg_qual'],weights=data['qual'])\n",
    "#     print(participant_mean)\n",
    "#     for a in left_daywise_data:\n",
    "#         a = a.sort_values('ltime').reset_index(drop=False)\n",
    "#         a['mean1'] = participant_mean\n",
    "#         a['diff1'] = a['mean1'] - a['stress_final']\n",
    "#         a['after'] = list(a['diff1'].values)[1:] + [np.nan]\n",
    "#         a['ind'] = 0\n",
    "#         a['ind'].loc[(a.diff1>0)&(a.after<0)] = -1\n",
    "#         a['ind'].loc[(a.diff1<0)&(a.after>0)] = 1\n",
    "        \n",
    "# #         for j,row in a.iterrows():\n",
    "# #             if row['ind']\n",
    "#         print(a.head())\n",
    "# #         print(a.head())\n",
    "# #         a.set_index('ltime',inplace=True)\n",
    "# #         a = a.resample('1min').mean().reset_index(drop=False)\n",
    "# #         print(a['ltime'].min(),a['ltime'].max(),a.columns)\n",
    "        \n",
    "#         plt.plot(a['ltime'],a['stress_final'])\n",
    "#         plt.hlines(participant_mean,a['ltime'].min(),a['ltime'].max())\n",
    "#         plt.plot(a['ltime'],a['ind'])\n",
    "#         plt.show()\n",
    "    ema = pickle.load(open(directory_ema+f,'rb'))\n",
    "    ema = ema.sort_values('score').reset_index(drop=True)\n",
    "    ema['label'][ema['score']<=np.mean(ema['score'])] = 0\n",
    "    ema['label'][ema['score']>np.mean(ema['score'])] = 1\n",
    "    pickle.dump([data,ema],open(directory2+f,'wb'))\n",
    "    return 0\n",
    "\n",
    "directory1 = '../../cc3/rice_data/after_computation/ecg_ppg_final_day_5/'\n",
    "directory2 = '../../cc3/rice_data/after_ema_parsing/ecg_ppg_final_pred_day_5/'\n",
    "if not os.path.isdir(directory2):\n",
    "    os.makedirs(directory2)\n",
    "directory_ema = '../../cc3/rice_data/ecg_ppg_ema_final/'\n",
    "from joblib import Parallel,delayed\n",
    "output = Parallel(n_jobs=30,verbose=3)(delayed(dump_data)(directory_ema,directory1,directory2,f) for f in os.listdir(directory1) if f[-1]=='p')    \n",
    "# output = [dump_data(directory_ema,directory1,directory2,f) for f in os.listdir(directory1) if f[-1]=='p']   \n",
    "#         plt.figure(figsize=(18,10))\n",
    "#         plt.plot(a['time'],a['stress_likelihood_ppg_qual'],'*-r')\n",
    "#         plt.plot(a['time'],a['hr']/np.max(a['hr']),'o-c')\n",
    "#         plt.title(np.max(a['hr']))\n",
    "#         plt.bar(a['time'],a['qual'],50)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  46 out of  78 | elapsed:    7.4s remaining:    5.2s\n",
      "[Parallel(n_jobs=30)]: Done  73 out of  78 | elapsed:   14.4s remaining:    1.0s\n",
      "[Parallel(n_jobs=30)]: Done  78 out of  78 | elapsed:   16.6s finished\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from joblib import Parallel,delayed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_episodes(directory_ema,directory1,directory2,f):\n",
    "    if f not in os.listdir(directory_ema):\n",
    "        return 0\n",
    "    data = pickle.load(open(directory1+f,'rb'))\n",
    "    a = data[0]\n",
    "    participant_mean = np.average(a['stress_final'],weights=a['qual'])\n",
    "    stress_days = [df for i,df in a.groupby(['hand','day'],as_index=False) if a.shape[0]>180]\n",
    "    this_participant = []\n",
    "    for a in stress_days:\n",
    "        a = a.sort_values('ltime').reset_index(drop=False)\n",
    "        a['mean1'] = participant_mean\n",
    "        a['diff1'] = a['mean1'] - a['stress_final']\n",
    "        a['after'] = list(a['diff1'].values)[1:] + [np.nan]\n",
    "        a['ind'] = 0\n",
    "        a['ind'].loc[(a.diff1>0)&(a.after<0)] = -1\n",
    "        a['ind'].loc[(a.diff1<0)&(a.after>0)] = 1\n",
    "#         plt.rcParams.update({'font.size':20})\n",
    "#         plt.figure(figsize=(18,10))\n",
    "#         plt.plot(a['ltime'],a['stress_final'],'*-r',label='Stress Likelihood')\n",
    "#         plt.hlines(participant_mean,a['ltime'].min(),a['ltime'].max(),label='Participant Average')\n",
    "#         a['stress_final1'] = a['stress_final']\n",
    "#         a['stress_final1'][a['stress_final1']<=participant_mean] = participant_mean\n",
    "#         plt.fill_between(a['ltime'],participant_mean,a['stress_final1'],label='Stress Episodes')\n",
    "#         plt.legend()\n",
    "#         plt.ylim([0,1])\n",
    "#         plt.show()\n",
    "        \n",
    "        if len(a['ind'].unique())==1:\n",
    "            continue\n",
    "        start = True\n",
    "        i = 0\n",
    "        k = -1\n",
    "        all_episodes = []\n",
    "        for j,row in a.iterrows():\n",
    "            if start:\n",
    "                if row['ind']==0:\n",
    "                    continue\n",
    "                elif row['ind'] ==-1:\n",
    "                    i = j\n",
    "                    start=False\n",
    "                elif row['ind'] == 1:\n",
    "                    i = 0\n",
    "                    k = j\n",
    "                    if k-i>4:\n",
    "                        temp = []\n",
    "                        temp.extend([row['user'],row['day'],row['hand'],row['time'],row['ltime'],a.loc[i:k]])\n",
    "#                         print(a.loc[i:k]['ind'])\n",
    "                        all_episodes.append(temp)\n",
    "                    start = False\n",
    "            else:\n",
    "                if row['ind']==0:\n",
    "                    continue\n",
    "                elif row['ind'] ==-1:\n",
    "                    i = j\n",
    "                elif row['ind'] == 1:\n",
    "                    k = j\n",
    "                    if k-i>4:\n",
    "                        temp = []\n",
    "                        temp.extend([row['user'],row['day'],row['hand'],row['time'],row['ltime'],a.loc[i:k]])\n",
    "#                         print(a.loc[i:k]['ind'])\n",
    "                        all_episodes.append(temp)\n",
    "        if k<i:\n",
    "            k = a.shape[0]\n",
    "            if k-i>4:\n",
    "                temp = []\n",
    "                temp.extend([a['user'].loc[int(i+k)//2],a['day'].loc[int(i+k)//2],\n",
    "                             a['hand'].loc[int(i+k)//2],a['time'].loc[int(i+k)//2],\n",
    "                             a['ltime'].loc[int(i+k)//2],a.loc[i:k]])\n",
    "                all_episodes.append(temp)\n",
    "        \n",
    "        data = pd.DataFrame(all_episodes,columns=['user','day','hand','time','ltime','data'])\n",
    "        for i,row in data.iterrows():\n",
    "            print(row['data']['ind'].values[0],row['data']['ind'].values[-1],row['data'].shape,a.shape)\n",
    "        print('-'*4)\n",
    "        this_participant.append(data)\n",
    "    data = pd.concat(this_participant).dropna().sort_values('time').reset_index(drop=True)\n",
    "    data['participant_mean'] = participant_mean\n",
    "    ema = pickle.load(open(directory_ema+f,'rb'))\n",
    "    ema = ema.sort_values('score').reset_index(drop=True)\n",
    "    ema['label'][ema['score']<=np.mean(ema['score'])] = 0\n",
    "    ema['label'][ema['score']>np.mean(ema['score'])] = 1\n",
    "    pickle.dump([data,ema],open(directory2+f,'wb'))\n",
    "    return 0\n",
    "\n",
    "directory1 = '../../cc3/rice_data/after_ema_parsing/ecg_ppg_final_pred_day_5/'\n",
    "directory2 = '../../cc3/rice_data/after_ema_parsing/ecg_ppg_episode_day_5/'\n",
    "directory_ema = '../../cc3/rice_data/ecg_ppg_ema_final/'\n",
    "if not os.path.isdir(directory2):\n",
    "    os.makedirs(directory2)\n",
    "# output = [make_episodes(directory_ema,directory1,directory2,f) for f in os.listdir(directory1) if f[-1]=='p']   \n",
    "output = Parallel(n_jobs=30,verbose=3)(delayed(make_episodes)(directory_ema,directory1,directory2,f) for f in os.listdir(directory1) if f[-1]=='p')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  46 out of  78 | elapsed:   10.2s remaining:    7.1s\n",
      "[Parallel(n_jobs=30)]: Done  73 out of  78 | elapsed:   21.2s remaining:    1.5s\n",
      "[Parallel(n_jobs=30)]: Done  78 out of  78 | elapsed:   24.4s finished\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel,delayed\n",
    "def get_expo(directory1,directory2,f):\n",
    "    if f[-1]!='p':\n",
    "        return 0\n",
    "    data,ema = pickle.load(open(directory1+f,'rb'))\n",
    "    ema = ema.sort_values('score').reset_index(drop=True)\n",
    "#     ema['happy'] = ema['all_scores'].apply(lambda a:a[0])\n",
    "#     ema['joyful'] = ema['all_scores'].apply(lambda a:a[1])\n",
    "#     ema['nervous'] = ema['all_scores'].apply(lambda a:a[2])\n",
    "#     ema['sad'] = ema['all_scores'].apply(lambda a:a[3])\n",
    "#     ema['angry'] = ema['all_scores'].apply(lambda a:a[4])\n",
    "#     labels = ema[['happy','joyful','nervous','sad','angry']].values\n",
    "#     for j in range(labels.shape[1]):\n",
    "#         t = labels[:,j]\n",
    "#         t[t<=np.mean(t)] = 0\n",
    "#         t[t!=0] = 1\n",
    "#         labels[:,j] = t\n",
    "#     labels = np.sum(labels,axis=1)\n",
    "#     labels[labels<=2] = 0\n",
    "#     labels[labels!=0] = 1\n",
    "#     ema['label'] = labels\n",
    "    all_data = []\n",
    "    for i,df in data.groupby(['hand','day'],as_index=False):\n",
    "        ema_day = ema[ema.day.isin(df['day'].values[:1])]\n",
    "        participant_mean = df['participant_mean'].values[0]\n",
    "        if ema_day.shape[0]==0:\n",
    "            continue\n",
    "#         print(df.shape,ema_day.shape)\n",
    "        df['start'] = df['data'].apply(lambda a:a['time'].min())\n",
    "        df['end'] = df['data'].apply(lambda a:a['time'].max())\n",
    "        df['density']  = df['data'].apply(lambda a:np.average(a['stress_final'],weights=a['qual']))\n",
    "        df['sum_density']  = df['data'].apply(lambda a:a['stress_final'].sum())\n",
    "        df['max_density']  = df['data'].apply(lambda a:a['stress_final'].max())\n",
    "        df['length_episode']  = df['data'].apply(lambda a:a.shape[0])\n",
    "        df['qual']  = df['data'].apply(lambda a:np.average(a['qual']))\n",
    "#         df = df[df.max_density>=2*participant_mean]\n",
    "        for j,row in ema_day.iterrows():\n",
    "            df_ema = df[(df.start<(row['time']-5*60))]\n",
    "            if df_ema.shape[0]==0:\n",
    "                temp = []\n",
    "                temp.extend([row['time'],df['user'].values[0],df['hand'].values[0],df['day'].values[0]])\n",
    "                distance = 0\n",
    "                temp.append(0)\n",
    "                temp.append(0)\n",
    "                temp.append(0)\n",
    "                temp.append(row['label'])\n",
    "                all_data.append(temp)\n",
    "                continue\n",
    "            for k,row1 in df_ema.iterrows():\n",
    "                temp = []\n",
    "                temp.extend([row['time'],df['user'].values[0],df['hand'].values[0],df['day'].values[0]])\n",
    "                if (row1['start']< row['time']) & (row1['end']<= row['time']):\n",
    "                    distance = ((row['time'] - row1['start']) + (row['time'] - row1['end']))/2\n",
    "                    temp.append(distance/3600)\n",
    "                    temp.append(row1['length_episode'])\n",
    "                    temp.append(row1['sum_density'])\n",
    "                    temp.append(row1['qual'])\n",
    "                    temp.append(row['label'])\n",
    "                    all_data.append(temp)\n",
    "                elif row1['end'] > row['time'] and row1['start'] < row['time']:\n",
    "                    distance = 0\n",
    "                    dd = row1['data']\n",
    "                    dd = dd[dd.time<=row['time']]\n",
    "                    temp.append(distance)\n",
    "                    temp.append(dd.shape[0])\n",
    "                    temp.append(dd['stress_final'].sum())\n",
    "                    temp.append(dd['qual'].mean())\n",
    "                    temp.append(row['label'])\n",
    "#                 if df['user'].values[0]=='8008f00d-2549-46e4-ab1f-01542c1076e2':\n",
    "#                     print(temp[1:])\n",
    "                    all_data.append(temp)\n",
    "            \n",
    "                \n",
    "                \n",
    "    data = pd.DataFrame(all_data,columns=['time','user','hand','day','distance','length_episode','sum_episode','qual','label'])\n",
    "    pickle.dump(data,open(directory2+f,'wb'))\n",
    "    return 0\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "directory1 = '../../cc3/rice_data/after_ema_parsing/ecg_ppg_episode_day_5/'\n",
    "directory2 = '../../cc3/rice_data/after_ema_parsing/ecg_ppg_exponential/'\n",
    "if not os.path.isdir(directory2):\n",
    "    os.makedirs(directory2)\n",
    "output = Parallel(n_jobs=30,verbose=3)(delayed(get_expo)(directory1,directory2,f) for f in os.listdir(directory1) if f[-1]=='p')  \n",
    "# output = [get_expo(directory1,directory2,f) for f in os.listdir(directory1) if f[:-2]=='8008f00d-2549-46e4-ab1f-01542c1076e2']\n",
    "#             print(df_ema.shape,'ema',df.shape,row['label'])         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 5\n",
      "[[ 3 10]\n",
      " [ 1  4]]\n",
      "---------------------------------------- 0.3384615384615385 0.4210526315789473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 2\n",
      "[[13  1]\n",
      " [ 1  1]]\n",
      "---------------------------------------- 0.7142857142857143 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 2.0\n",
      "[[0 9]\n",
      " [0 2]]\n",
      "---------------------------------------- 0.6111111111111112 0.3076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 22\n",
      "[[ 0  4]\n",
      " [ 0 22]]\n",
      "---------------------------------------- 0.3977272727272727 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 3.0\n",
      "[[1 7]\n",
      " [0 3]]\n",
      "---------------------------------------- 0.5 0.4615384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 2.0\n",
      "[[ 1 10]\n",
      " [ 0  2]]\n",
      "---------------------------------------- 0.6363636363636364 0.2857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 11.0\n",
      "[[ 2 11]\n",
      " [ 2  9]]\n",
      "---------------------------------------- 0.6993006993006994 0.5806451612903226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 5.0\n",
      "[[1 3]\n",
      " [1 4]]\n",
      "---------------------------------------- 0.65 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 3.0\n",
      "[[ 3 16]\n",
      " [ 1  2]]\n",
      "---------------------------------------- 0.5789473684210527 0.1904761904761905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 6.0\n",
      "[[9 5]\n",
      " [2 4]]\n",
      "---------------------------------------- 0.7440476190476191 0.5333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 16\n",
      "[[ 3  1]\n",
      " [ 3 13]]\n",
      "---------------------------------------- 0.65625 0.8666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 13\n",
      "[[13  1]\n",
      " [ 9  4]]\n",
      "---------------------------------------- 0.5989010989010989 0.4444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 18.0\n",
      "[[ 0  3]\n",
      " [ 1 17]]\n",
      "---------------------------------------- 0.38888888888888895 0.8947368421052632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 6.0\n",
      "[[ 1 18]\n",
      " [ 0  6]]\n",
      "---------------------------------------- 0.868421052631579 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 15.0\n",
      "[[ 1  0]\n",
      " [ 1 14]]\n",
      "---------------------------------------- 1.0 0.9655172413793104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 4.0\n",
      "[[ 0 12]\n",
      " [ 0  4]]\n",
      "---------------------------------------- 0.5 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 3.0\n",
      "[[ 0 17]\n",
      " [ 0  3]]\n",
      "---------------------------------------- 0.803921568627451 0.2608695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 20.0\n",
      "[[ 0 15]\n",
      " [ 0 20]]\n",
      "---------------------------------------- 0.6466666666666667 0.7272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 17.0\n",
      "[[ 9  3]\n",
      " [ 5 12]]\n",
      "---------------------------------------- 0.7990196078431373 0.7500000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 25.0\n",
      "[[ 7  6]\n",
      " [15 10]]\n",
      "---------------------------------------- 0.5261538461538462 0.48780487804878053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 11.0\n",
      "[[ 5 15]\n",
      " [ 2  9]]\n",
      "---------------------------------------- 0.5181818181818182 0.5142857142857142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 12.0\n",
      "[[18  8]\n",
      " [ 7  5]]\n",
      "---------------------------------------- 0.5689102564102564 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 20.0\n",
      "[[ 0  8]\n",
      " [ 0 20]]\n",
      "---------------------------------------- 0.6 0.8333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 6.0\n",
      "[[29 14]\n",
      " [ 4  2]]\n",
      "---------------------------------------- 0.5697674418604651 0.18181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 6.0\n",
      "[[ 0 30]\n",
      " [ 0  6]]\n",
      "---------------------------------------- 0.7888888888888889 0.2857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 4.0\n",
      "[[ 0 21]\n",
      " [ 0  4]]\n",
      "---------------------------------------- 0.47619047619047616 0.2758620689655173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 11\n",
      "[[12  6]\n",
      " [ 9  2]]\n",
      "---------------------------------------- 0.4267676767676768 0.2105263157894737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 20.0\n",
      "[[17  7]\n",
      " [12  8]]\n",
      "---------------------------------------- 0.5895833333333333 0.4571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 24.0\n",
      "[[ 0 17]\n",
      " [ 0 24]]\n",
      "---------------------------------------- 0.3651960784313726 0.7384615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    5.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 17.0\n",
      "[[ 0 35]\n",
      " [ 0 17]]\n",
      "---------------------------------------- 0.5294117647058824 0.4927536231884058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    5.8s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 23.0\n",
      "[[ 0 39]\n",
      " [ 0 23]]\n",
      "---------------------------------------- 0.7157190635451504 0.5411764705882353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 5.0\n",
      "[[ 0 17]\n",
      " [ 1  4]]\n",
      "---------------------------------------- 0.3999999999999999 0.3076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 20.0\n",
      "[[ 0 20]\n",
      " [ 0 20]]\n",
      "---------------------------------------- 0.5575 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 6.0\n",
      "[[20 11]\n",
      " [ 2  4]]\n",
      "---------------------------------------- 0.6075268817204301 0.3809523809523809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 10.0\n",
      "[[ 1  9]\n",
      " [ 0 10]]\n",
      "---------------------------------------- 0.9099999999999999 0.6896551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 17.0\n",
      "[[ 0 14]\n",
      " [ 1 16]]\n",
      "---------------------------------------- 0.3529411764705882 0.6808510638297872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 6.0\n",
      "[[19 18]\n",
      " [ 2  4]]\n",
      "---------------------------------------- 0.8063063063063063 0.28571428571428575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 13.0\n",
      "[[ 0 17]\n",
      " [ 0 13]]\n",
      "---------------------------------------- 0.6334841628959276 0.6046511627906976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  49 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 209 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 9.0\n",
      "[[15  6]\n",
      " [ 1  8]]\n",
      "---------------------------------------- 0.8941798941798942 0.6956521739130435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 20.0\n",
      "[[ 0 25]\n",
      " [ 0 20]]\n",
      "---------------------------------------- 0.404 0.6153846153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 6.0\n",
      "[[ 0 10]\n",
      " [ 0  6]]\n",
      "---------------------------------------- 0.6499999999999999 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 11.0\n",
      "[[6 0]\n",
      " [5 6]]\n",
      "---------------------------------------- 0.7272727272727273 0.7058823529411764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.8s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 21.0\n",
      "[[13  5]\n",
      " [13  8]]\n",
      "---------------------------------------- 0.6005291005291006 0.47058823529411764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    6.6s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 20.0\n",
      "[[ 0 50]\n",
      " [ 0 20]]\n",
      "---------------------------------------- 0.372 0.4444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 4\n",
      "[[ 1 27]\n",
      " [ 0  4]]\n",
      "---------------------------------------- 0.7946428571428572 0.2285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 18.0\n",
      "[[ 0 19]\n",
      " [ 0 18]]\n",
      "---------------------------------------- 0.8011695906432749 0.6545454545454547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 12.0\n",
      "[[ 3 43]\n",
      " [ 2 10]]\n",
      "---------------------------------------- 0.5507246376811594 0.3076923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 29.0\n",
      "[[ 4  4]\n",
      " [15 14]]\n",
      "---------------------------------------- 0.5474137931034483 0.5957446808510638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=40)]: Done 336 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    3.5s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 31.0\n",
      "[[ 5  1]\n",
      " [13 18]]\n",
      "---------------------------------------- 0.6666666666666667 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 4.0\n",
      "[[ 0 74]\n",
      " [ 0  4]]\n",
      "---------------------------------------- 0.30405405405405406 0.09756097560975609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    5.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 8\n",
      "[[26 22]\n",
      " [ 4  4]]\n",
      "---------------------------------------- 0.5989583333333333 0.23529411764705882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    8.3s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 40.0\n",
      "[[ 2 50]\n",
      " [ 4 36]]\n",
      "---------------------------------------- 0.5326923076923077 0.5714285714285715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    6.9s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 32.0\n",
      "[[26 13]\n",
      " [21 11]]\n",
      "---------------------------------------- 0.5480769230769231 0.39285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 38.0\n",
      "[[ 6 33]\n",
      " [ 7 31]]\n",
      "---------------------------------------- 0.4750337381916329 0.6078431372549019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done  48 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=40)]: Done 208 tasks      | elapsed:    4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 48.0\n",
      "[[ 0 52]\n",
      " [ 0 48]]\n",
      "---------------------------------------- 0.5552884615384615 0.6486486486486487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done 500 out of 500 | elapsed:    8.8s finished\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import numpy as np\n",
    "from joblib import Parallel,delayed\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "all_data = []\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,f1_score,roc_curve,auc,precision_score,recall_score,accuracy_score,classification_report,make_scorer,precision_recall_curve\n",
    "def my_score_auc(y_true,y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    return auc(fpr,tpr)\n",
    "\n",
    "def f1Bias_scorer_CV_2(probs, y, ret_bias=False):\n",
    "    fpr, tpr, thresholds = roc_curve(y, probs)\n",
    "    f1 = 0.0\n",
    "    bias = 0\n",
    "    for i in range(0, len(thresholds)):\n",
    "        temp_y_pred = deepcopy(y)\n",
    "        temp_y_pred[temp_y_pred>thresholds[i]] = 1\n",
    "        temp_y_pred[temp_y_pred<=thresholds[i]] = 0\n",
    "        f = f1_score(y,np.int32(temp_y_pred))\n",
    "        if f > f1:\n",
    "            f1 = f\n",
    "            bias = thresholds[i]\n",
    "\n",
    "    if ret_bias:\n",
    "        return f1, bias\n",
    "    else:\n",
    "        return f1\n",
    "\n",
    "def get_auc(data,p):\n",
    "    label_col = []\n",
    "    y_pred = []\n",
    "    for i,df1 in data.groupby(['day','user','hand','time'],as_index=False):\n",
    "        df = df1[['label','sum_episode','distance']].dropna()\n",
    "        if df.shape[0]==0:\n",
    "            continue\n",
    "        label_col.append(df['label'].unique()[0])\n",
    "        y_pred.append(np.sum(df['sum_episode']*np.exp(-1*(df['distance']/p))))\n",
    "    try:\n",
    "        print(len(label_col))\n",
    "        return my_score_auc(label_col,y_pred),label_col,y_pred\n",
    "    except:\n",
    "        return 0\n",
    "def get_all_auc(directory2,f):\n",
    "    data = pickle.load(open(directory2+f,'rb'))\n",
    "    if len(data['label'].unique())==1:\n",
    "        return -1\n",
    "    if len(data['time'].unique())<10:\n",
    "        return -1\n",
    "    auc_col_all = Parallel(n_jobs=40,verbose=3)(delayed(get_auc)(data,p) for p in np.linspace(.0001,5,500))\n",
    "    auc_all = np.array([a[0] for a in auc_col_all if a[0]!=np.nan])\n",
    "    ind_max = np.argmax(auc_all)\n",
    "    y,probs = auc_col_all[ind_max][1:]\n",
    "    if len(np.unique(y))==1:\n",
    "        return -1\n",
    "    print(len(probs),sum(y))\n",
    "    a,b = f1Bias_scorer_CV_2(np.array(probs), np.array(y), ret_bias=True)\n",
    "    probs = np.array(probs)\n",
    "    probs[probs<=b] = 0\n",
    "    probs[probs>b] = 1\n",
    "    print(confusion_matrix(y,probs))\n",
    "    print('--'*20,np.max(auc_all),f1_score(y,probs))\n",
    "    return np.max(auc_all)\n",
    "\n",
    "\n",
    "directory2 = '../../cc3/rice_data/after_ema_parsing/ecg_ppg_exponential/'\n",
    "\n",
    "# auc_col = Parallel(n_jobs=30,verbose=3)(delayed(get_all_auc)(directory2,f) for f in os.listdir(directory2) if f[-1]=='p')  \n",
    "auc_col = [get_all_auc(directory2,f) for f in os.listdir(directory2) if f[-1]=='p']\n",
    "auc_col = np.array(auc_col)\n",
    "auc_col = auc_col[auc_col>-1]\n",
    "#     print(data)\n",
    "#     import matplotlib.pyplot as plt\n",
    "# #     plt.figure(figsize=(12,8))\n",
    "# #     # sns.jointplot(x='distance', y='sum_episode', kind=\"hex\", color=\"k\",data=data[data.label==0])\n",
    "# #     plt.boxplot([data[data.label==1]['distance'],data[data.label==0]['distance']],showfliers=False)\n",
    "# #     plt.show()\n",
    "    \n",
    "#     plt.figure(figsize=(12,8))\n",
    "#     plt.hist(data[data.label>=1]['distance'],density=True,alpha=.5,label='Stress')\n",
    "#     plt.hist(data[data.label<=0]['distance'],density=True,alpha=.5,label='Not Stress')\n",
    "#     plt.legend()\n",
    "#     # plt.xticks(rotation=10)\n",
    "#     plt.show()\n",
    "#     print('-'*400)\n",
    "#     all_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 55 artists>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABBEAAAI/CAYAAAAhjUEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAbHUlEQVR4nO3df6zd933X8dd7vi1DW1lZ440pjneD5gHWGO1kZZ06idJ1KJmnBIkyJWPQoTL/s6CijaE7QN0ImuSC2ChS+BF1VbsJmoXChoWNsqoLKkI0JKHt1iQUvOARh7LQri2giZawN3/ck+1y68RvX5/rc+z7eEhRzvd7vufed6WveuKnP9/vt7o7AAAAAJfzZaseAAAAALg+iAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMDIxqp+8U033dSbm5ur+vUAAADAJTzxxBOf7u7Dl3pvZRFhc3Mzjz/++Kp+PQAAAHAJVfVrL/WeyxkAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGLlsRKiq91TV81X1iZd4v6rq71bV+ar65ar6luWPCQAAAKzaZCXCe5Pc/jLv35Hk2OKfU0n+/tWPBQAAAKyby0aE7v5wkt94mUPuSvIzve0jSV5dVV+3rAEBAACA9bCMeyLcnOTZHdsXF/sAAACAG8jGtfxlVXUq25c85OjRo9fyVwMAAMCebW6d3dPnLpw+ueRJVmsZKxGeS3LLju0ji31forsf6O4T3X3i8OHDS/jVAAAAwLWyjIhwJsmfXTyl4fVJPt/dn1rCzwUAAADWyGUvZ6iq9yd5Y5Kbqupikh9L8ook6e5/kORcku9Kcj7Jbyb5c/s1LAAAALA6l40I3X3PZd7vJD+4tIkAAACAtbSMyxkAAACAA0BEAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARjZWPQAAAADst82ts1f8mQunT+7DJNc3KxEAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAkY1VDwAAAAAvZ3Pr7BV/5sLpk/swCVYiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMLKx6gEAAAC4sW1unb3iz1w4fXIfJuFqWYkAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjGxMDqqq25O8K8mhJO/u7tO73j+a5H1JXr04Zqu7zy15VgAAAK6xza2zV/yZC6dP7sMkrIPLrkSoqkNJ7k9yR5LjSe6pquO7DvtrSR7q7tcluTvJ31v2oAAAAMBqTVYi3JbkfHc/kyRV9WCSu5I8teOYTvJ7Fq+/Ksl/XeaQAAAAXLm9rCJIrCTgpU0iws1Jnt2xfTHJt+465seT/GJV/YUkX5HkzUuZDgAA4ABzKQHrZnRPhIF7kry3u/92VX1bkp+tqm/q7t/aeVBVnUpyKkmOHj26pF8NAACwfgQAbkSTpzM8l+SWHdtHFvt2eluSh5Kku/9tki9PctPuH9TdD3T3ie4+cfjw4b1NDAAAAKzEZCXCY0mOVdWt2Y4Hdyf53l3H/Jck35HkvVX1h7IdEf77MgcFAAC4VtxLAC7tsisRuvuFJPcmeTjJ09l+CsOTVXVfVd25OOyHk/xAVX08yfuTfH93934NDQAAAFx7o3sidPe5JOd27XvHjtdPJXnDckcDAAAA1smybqwIAACwNtzUEPbH5MaKAAAAACICAAAAMCMiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjG6seAAAAYKfNrbNX/JkLp0/uwyTAblYiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMbqx4AAAC4cWxund3T5y6cPrnkSYD9YCUCAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAw4ukMAADAb9vL0xU8WQEODhEBAABuEAIAsN9czgAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMbKx6AAAAINncOrunz104fXLJkwC8NCsRAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAY2Vj1AAAAcCPY3Dp7xZ+5cPrkPkwCsH+sRAAAAABGRAQAAABgREQAAAAARkQEAAAAYMSNFQEAOPDcFBFgxkoEAAAAYEREAAAAAEZczgAAwEpd7aUEe/n87p8BwIyVCAAAAMCIlQgAAOyZGxICHCxWIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMOLGigAAB5RHIwJwpaxEAAAAAEasRAAAuE55vCIA15qVCAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjGysegAAgINoc+vsFX/mwumT+zAJAMxZiQAAAACMjFYiVNXtSd6V5FCSd3f36Usc8z1JfjxJJ/l4d3/vEucEAFgbe1lFkFhJAMD177IRoaoOJbk/yXcmuZjksao6091P7TjmWJIfTfKG7v5sVX3Nfg0MAAAArMbkcobbkpzv7me6+4tJHkxy165jfiDJ/d392STp7ueXOyYAAACwapOIcHOSZ3dsX1zs2+kbk3xjVf2bqvrI4vIHAAAA4AayrKczbCQ5luSNSY4k+XBV/eHu/tzOg6rqVJJTSXL06NEl/WoA4CBZxlMNPBkBAPZmEhGeS3LLju0ji307XUzyaHf/nyT/uar+Y7ajwmM7D+ruB5I8kCQnTpzovQ4NAKzG1f7h2w0JAeD6Nrmc4bEkx6rq1qp6ZZK7k5zZdcwvZHsVQqrqpmxf3vDMEucEAAAAVuyyEaG7X0hyb5KHkzyd5KHufrKq7quqOxeHPZzkM1X1VJJHkvxId39mv4YGAAAArr3RPRG6+1ySc7v2vWPH607yQ4t/AAAAgBvQ5HIGAAAAgKU9nQEAWHOeSAAAXC0rEQAAAIAREQEAAAAYEREAAACAEREBAAAAGHFjRQC4DuzlpoiJGyMCAMtlJQIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACNurAgAl7GXmxruvqHhMn4GAMCqWYkAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMeDoDADe0vTwVIfFkBACASxERAFhrHo0IALA+XM4AAAAAjIgIAAAAwIjLGQDYNy5FAAC4sYgIADeoq/0DvBsSAgCwm8sZAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgJGNVQ8AwJfa3Dp7xZ+5cPrkPkwCAAC/w0oEAAAAYMRKBIAl28sqgsRKAgAA1p+IALCLSwkAAODSXM4AAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIGysCNxQ3RQQAgP1jJQIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIxurHgC4cWxunb3iz1w4ffKqPr/7ZwAAAPvHSgQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBkY9UDAOthc+vsFX/mwumT+zAJAACwrkQEuAHsJQAkIgAAAHBlXM4AAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAyMaqBwCSza2zV/yZC6dP7sMkAAAAL81KBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgZBQRqur2qvpkVZ2vqq2XOe5PVlVX1YnljQgAAACsg8tGhKo6lOT+JHckOZ7knqo6fonjXpXk7UkeXfaQAAAAwOptDI65Lcn57n4mSarqwSR3JXlq13F/I8k7k/zIUieENbe5dfaKP3Ph9Ml9mAQAAGB/TS5nuDnJszu2Ly72/baq+pYkt3T3lf9pCgAAALguTFYivKyq+rIkP5nk+wfHnkpyKkmOHj16tb8artpeVhEkVhIAAAAH0yQiPJfklh3bRxb7XvSqJN+U5F9VVZL8viRnqurO7n585w/q7geSPJAkJ06c6KuYG5K4lAAAAOBamlzO8FiSY1V1a1W9MsndSc68+GZ3f767b+ruze7eTPKRJF8SEAAAAIDr22UjQne/kOTeJA8neTrJQ939ZFXdV1V37veAAAAAwHoY3ROhu88lObdr3zte4tg3Xv1YAAAAwLq56hsrwl65nwEAAMD1ZXJPBAAAAAARAQAAAJgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABjZWPUAXJ82t87u6XMXTp9c8iQAAABcK1YiAAAAACMiAgAAADAiIgAAAAAj7olwQO3lngbuZwAAAHCwWYkAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMeDrDdciTFQAAAFgFKxEAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAkY1VD3DQbG6d3dPnLpw+ueRJAAAA4MpYiQAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjIgIAAAAwMjGqge43mxunb3iz1w4fXIfJgEAAIBry0oEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYEREAAAAAEZEBAAAAGBERAAAAABGRAQAAABgREQAAAAARkQEAAAAYGQUEarq9qr6ZFWdr6qtS7z/Q1X1VFX9clV9qKq+fvmjAgAAAKt02YhQVYeS3J/kjiTHk9xTVcd3HfbRJCe6+5uTfCDJ31z2oAAAAMBqTVYi3JbkfHc/091fTPJgkrt2HtDdj3T3by42P5LkyHLHBAAAAFZtEhFuTvLsju2Li30v5W1J/uXVDAUAAACsn41l/rCq+r4kJ5L80Zd4/1SSU0ly9OjRZf5qAAAAYJ9NViI8l+SWHdtHFvv+P1X15iR/Ncmd3f2FS/2g7n6gu09094nDhw/vZV4AAABgRSYR4bEkx6rq1qp6ZZK7k5zZeUBVvS7JP8x2QHh++WMCAAAAq3bZiNDdLyS5N8nDSZ5O8lB3P1lV91XVnYvD/laSr0zyT6rqY1V15iV+HAAAAHCdGt0TobvPJTm3a987drx+85LnAgAAANbM5HIGAAAAABEBAAAAmBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAIAREQEAAAAYEREAAACAEREBAAAAGBERAAAAgBERAQAAABgREQAAAICRUUSoqtur6pNVdb6qti7x/u+qqp9bvP9oVW0ue1AAAABgtS4bEarqUJL7k9yR5HiSe6rq+K7D3pbks939DUl+Ksk7lz0oAAAAsFqTlQi3JTnf3c909xeTPJjkrl3H3JXkfYvXH0jyHVVVyxsTAAAAWLVJRLg5ybM7ti8u9l3ymO5+Icnnk7xmGQMCAAAA66G6++UPqHpLktu7+88vtv9Mkm/t7nt3HPOJxTEXF9u/ujjm07t+1qkkpxabfyDJJ5f1P2QN3JTk05c9Cq495ybryrnJOnJesq6cm6wr5+aN6eu7+/Cl3tgYfPi5JLfs2D6y2HepYy5W1UaSr0rymd0/qLsfSPLAZOLrTVU93t0nVj0H7ObcZF05N1lHzkvWlXOTdeXcPHgmlzM8luRYVd1aVa9McneSM7uOOZPkrYvXb0nyS325JQ4AAADAdeWyKxG6+4WqujfJw0kOJXlPdz9ZVfcleby7zyT56SQ/W1Xnk/xGtkMDAAAAcAOZXM6Q7j6X5Nyufe/Y8fp/J/lTyx3tunNDXqbBDcG5ybpybrKOnJesK+cm68q5ecBc9saKAAAAAMnsnggAAAAAIsIyVNXtVfXJqjpfVVurnoeDq6reU1XPLx67+uK+r66qD1bVf1r8+/euckYOnqq6paoeqaqnqurJqnr7Yr9zk5Wqqi+vqn9XVR9fnJt/fbH/1qp6dPG9/nOLG0vDNVVVh6rqo1X1LxbbzktWrqouVNWvVNXHqurxxT7f5weMiHCVqupQkvuT3JHkeJJ7qur4aqfiAHtvktt37dtK8qHuPpbkQ4ttuJZeSPLD3X08yeuT/ODi/yedm6zaF5K8qbv/SJLXJrm9ql6f5J1Jfqq7vyHJZ5O8bYUzcnC9PcnTO7adl6yLP9bdr93xWEff5weMiHD1bktyvruf6e4vJnkwyV0rnokDqrs/nO0npOx0V5L3LV6/L8mfuKZDceB196e6+98vXv/PbP9H8c1xbrJive1/LTZfsfink7wpyQcW+52bXHNVdSTJySTvXmxXnJesL9/nB4yIcPVuTvLsju2Li32wLr62uz+1eP3fknztKofhYKuqzSSvS/JonJusgcWS8Y8leT7JB5P8apLPdfcLi0N8r7MKfyfJX07yW4vt18R5yXroJL9YVU9U1anFPt/nB8zoEY/AjaG7u6o8koWVqKqvTPJPk/zF7v4f23+xts25yap09/9N8tqqenWSn0/yB1c8EgdcVX13kue7+4mqeuOq54Fdvr27n6uqr0nywar6Dzvf9H1+MFiJcPWeS3LLju0ji32wLn69qr4uSRb/fn7F83AAVdUrsh0Q/lF3/7PFbucma6O7P5fkkSTfluTVVfXiX7T4Xudae0OSO6vqQrYvk31TknfFecka6O7nFv9+Ptvh9bb4Pj9wRISr91iSY4s75r4yyd1Jzqx4JtjpTJK3Ll6/Nck/X+EsHECLa3l/OsnT3f2TO95ybrJSVXV4sQIhVfW7k3xntu/Z8UiStywOc25yTXX3j3b3ke7ezPZ/V/5Sd//pOC9Zsar6iqp61Yuvk/zxJJ+I7/MDp7qtNrlaVfVd2b527VCS93T3T6x4JA6oqnp/kjcmuSnJryf5sSS/kOShJEeT/FqS7+nu3TdfhH1TVd+e5F8n+ZX8zvW9fyXb90VwbrIyVfXN2b4J2KFs/8XKQ919X1X9/mz/DfBXJ/loku/r7i+sblIOqsXlDH+pu7/becmqLc7Bn19sbiT5x939E1X1mvg+P1BEBAAAAGDE5QwAAADAiIgAAAAAjIgIAAAAwIiIAAAAAIyICAAAAMCIiAAAAACMiAgAAADAiIgAAAAAjPw/T0UzBQpoHvoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "plt.bar(np.arange(len(auc_col)),sorted(auc_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5989010989010989"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(auc_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.distance<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(18,10))\n",
    "# sns.jointplot(x='distance', y='sum_episode', kind=\"hex\", color=\"k\",data=data[data.label==0])\n",
    "plt.boxplot([data[data.label==1]['distance'],data[data.label==0]['distance']],showfliers=False)\n",
    "plt.show()\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.hist(data[data.label==1]['distance'],30,density=True)\n",
    "plt.hist(data[data.label==0]['distance'],30,density=True)\n",
    "# plt.xticks(rotation=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3 High Performance",
   "language": "python",
   "name": "cc3_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
